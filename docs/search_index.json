[["index.html", "Proteomics Data Analysis in R/Bioconductor Welcome!", " Proteomics Data Analysis in R/Bioconductor Tyler Sagendorf May 27, 2022 Welcome! This tutorial is very much a work-in progress. Even sections that appear finished are likely to be changed. I will update this when significant progress is made. Thank you for your patience. It is highly recommended to review the resources below before continuing with the rest of the tutorial. Proteomics Overview Protein Analysis by Shotgun/Bottom-up Proteomics Modern Proteomics – Sample Preparation, Analysis and Practical Applications Liquid Chromatography Mass Spectrometry-Based Proteomics: Biological and Technological Aspects Mass Spectrometry Warwick School of Life Sciences Teaching Animations Tandem Mass Spectrometry for Peptide and Protein Sequence Analysis Maestro: Comprehensive, Multi-Stage Spectrum Identification in Protein Mass Spectrometry Searching databases for protein identification - part 1 (YouTube video) Mass spectrometry for proteomics - part one (YouTube video) Electrospray Ionisation Mass Spectrometry: Principles and Clinical Applications PNNL’s Data Management System (DMS) Integrative Omics PRISMWiki Universal Protein Resource (UniProt): protein sequence and annotation data False Discovery Rate (FDR) How to talk about protein‐level false discovery rates in shotgun proteomics Posterior Error Probabilities and False Discovery Rates: Two Sides of the Same Coin False Discovery Rate: PEAKS FDR Estimation False discovery rates in spectral identification RStudio Cheatsheets Pattern matching with regular expressions R for Data Science: Strings RegexOne: Learn Regular Expressions with simple, interactive exercises. "],["iso-global.html", "Section 1 Isobaric Quantification: Proteomics", " Section 1 Isobaric Quantification: Proteomics This pipeline shows how to process global proteomics TMT data with PlexedPiper. We will use data package 3442, which is “PlexedPiperTestData global”. In addition to PlexedPiper, we will also need MSnID (the basis for PlexedPiper) and PNNL.DMS.utils to interface with PNNL’s DMS. ## Install missing packages if (!require(&quot;remotes&quot;, quietly = T)) install.packages(&quot;remotes&quot;) git_packages &lt;- c(&quot;MSnID@pnnl-master&quot;, &quot;PlexedPiper&quot;, &quot;PNNL.DMS.utils&quot;) for (pkg_i in git_packages) { if (!require(sub(&quot;@.*&quot;, &quot;&quot;, pkg_i), quietly = T, character.only = T)) remotes::install_github(file.path(&quot;PNNL-Comp-Mass-Spec&quot;, pkg_i)) } ## ------------------------ library(MSnID) library(PlexedPiper) library(PNNL.DMS.utils) The pipeline can be broken up into four major parts: prepare MS/MS identifications, prepare reporter ion intensities, create study design tables, and create a quantitative cross-tab. There is another step that is required for statistical testing, which is to create an MSnSet. "],["prepare-msms-identifications.html", "1.1 Prepare MS/MS Identifications", " 1.1 Prepare MS/MS Identifications 1.1.1 Read MS-GF+ Data The first step in the preparation of the MS/MS identifications is to fetch the data. This can either be obtained from PNNL’s DMS or from a local folder. If working with the DMS, use PNNL.DMS.utils::read_msgf_data_from_DMS; otherwise, use PlexedPiper::read_msgf_data. ## Get MS-GF+ results from local folder - not run # Get file path path_to_MSGF_results &lt;- &quot;path_to_msgf_results&quot; # Read MS-GF+ data from path msnid &lt;- read_msgf_data(path_to_MSGF_results) ## Get MS-GF+ results from DMS data_package_num &lt;- 3442 # global proteomics msnid &lt;- read_msgf_data_from_DMS(data_package_num) # global proteomics Normally, this would display a progress bar in the console as the data is being fetched. However, the output was suppressed to save space. We can view a summary of the MSnID object with the show() function. show(msnid) ## MSnID object ## Working directory: &quot;.&quot; ## #Spectrum Files: 48 ## #PSMs: 1156754 at 31 % FDR ## #peptides: 511617 at 61 % FDR ## #accessions: 128378 at 98 % FDR This summary tells us that msnid consists of 4 spectrum files (datasets), and contains a total of 1,156,754 peptide-spectrum-matches (PSMs), 511,617 total peptides, and 128,378 total accessions (proteins). The reported FDR is the empirical false-discovery rate, which is calculated as the ratio of the number of unique decoy to unique non-decoy PSMs, peptides, or accessions. 1.1.2 Correct Isotope Selection Error Carbon has two stable isotopes: \\(^{12}\\text{C}\\) and \\(^{13}\\text{C}\\), with natural abundances of 98.93% and 1.07%, respectively (Berglund et al., 2011). That is, we expect that about 1 out of every 100 carbon atoms is naturally going to be a \\(^{13}\\text{C}\\), while the rest are \\(^{12}\\text{C}\\). In larger peptides with many carbon atoms, it is more likely that at least one atom will be a \\(^{13}\\text{C}\\) than all atoms will be \\(^{12}\\text{C}\\). In cases such as these, a non-monoisotopic ion will be selected by the instrument for fragmentation. Figure 1.1: MS1 spectra with peak at non-monoisotopic precursor ion. In Figure 1.1, the monoisotopic ion (m/z of 1427.29) is not the most abundant, so it is not selected as the precursor. Instead, the ion with a \\(^{13}\\text{C}\\) in place of a \\(^{12}\\text{C}\\) is selected for fragmentation. We calculate the mass difference between these two ions as the difference between the mass-to-charge ratios multiplied by the ion charge. In this case, the mass difference is 1 Dalton, or about the difference between \\(^{13}\\text{C}\\) and \\(^{12}\\text{C}\\). (More accurately, the difference between these isotopes is 1.0033548378 Da.) While MS-GF+ is still capable of correctly identifying these peptides, the downstream calculations of mass measurement error need to be fixed because they are used for filtering later on (Section 1.1.4). The correct_peak_selection function corrects these mass measurement errors, and Figure 1.2 shows the distribution of the absolute mass measurement errors (in PPM) before and after correction. This step influences the results of the peptide-level FDR filter. # Correct for isotope selection error msnid &lt;- correct_peak_selection(msnid) Figure 1.2: Histogram of mass measurement errors before and after correction. 1.1.3 Remove Contaminants Now, we will remove contaminants such as the trypsin that was used for protein digestion. We can see which contaminants will be removed with accessions(msnid)[grepl(\"Contaminant\", accessions(msnid))]. To remove contaminants, we use apply_filter with an appropriate string that tells the function what rows to keep. In this case, we keep rows where the accession does not contain “Contaminant”. We will use show to see how the counts change. This step is performed toward the beginning so that contaminants are not selected over other proteins in the filtering or parsimonious inference steps—only to be removed later on. # Remove contaminants msnid &lt;- apply_filter(msnid, &quot;!grepl(&#39;Contaminant&#39;, accession)&quot;) show(msnid) ## MSnID object ## Working directory: &quot;.&quot; ## #Spectrum Files: 48 ## #PSMs: 1155442 at 31 % FDR ## #peptides: 511196 at 61 % FDR ## #accessions: 128353 at 98 % FDR We can see that the number of PSMs decreased by about 1300, peptides by ~400, and proteins by 25. 1.1.4 MS/MS ID Filter: Peptide Level The next step is to filter the MS/MS identifications such that the empirical peptide-level FDR is less than some threshold and the number of identifications is maximized. We will use the \\(-log_{10}\\) of the PepQValue column as one of our filtering criteria and assign it to a new column in psms(msnid) called msmsScore. The PepQValue column is the MS-GF+ Spectrum E-value, which reflects how well the theoretical and experimental fragmentation spectra match; therefore, high values of msmsScore indicate a good match (see Figure 1.3). Figure 1.3: Density plot of msmsScore. The other filtering criteria is the absolute deviation of the mass measurement error of the precursor ions in parts-per-million (ppm), which is assigned to the absParentMassErrorPPM column in psms(msnid) (see Figure 1.4). Figure 1.4: Density plot of absParentMassErrorPPM. These new columns msmsScore and absParentMassErrorPPM are generated automatically by filter_msgf_data, so we don’t need to worry about creating them ourselves. # 1% FDR filter at the peptide level msnid &lt;- filter_msgf_data(msnid, level = &quot;peptide&quot;, fdr.max = 0.01) show(msnid) ## MSnID object ## Working directory: &quot;.&quot; ## #Spectrum Files: 48 ## #PSMs: 471295 at 0.46 % FDR ## #peptides: 96663 at 1 % FDR ## #accessions: 27098 at 9.1 % FDR We can see that filtering drastically reduces the number of PSMs, and the empirical peptide-level FDR is now 1%. However, notice that the empirical protein-level FDR is still fairly high. 1.1.5 MS/MS ID Filter: Protein Level (This step can be skipped if the final cross-tab will be at the peptide level.) Now, we need to filter proteins so that the FDR is at most 1%. For each protein, we divide the number of associated peptides by its length and multiply this value by 1000. This new peptides_per_1000aa column is used as the filter criteria (Figure 1.6). We will need the lengths of each protein, which can be obtained from the FASTA (pronounced FAST-AYE) file that contains the protein sequences used in the database search. The first three entries of the FASTA file are shown in Figure 1.5. Figure 1.5: First three entries of the FASTA file. The path to the FASTA file can be specified as a local file path or it can be obtained with PNNL.DMS.utils::path_to_FASTA_used_by_DMS. We will use the latter method. ## Get path to FASTA file from local folder - not run path_to_FASTA &lt;- &quot;some_folder/name_of_fasta_file.fasta&quot; ## Get path to FASTA file from DMS path_to_FASTA &lt;- path_to_FASTA_used_by_DMS(data_package_num) # Compute number of peptides per 1000 amino acids msnid &lt;- compute_num_peptides_per_1000aa(msnid, path_to_FASTA) Figure 1.6: Density plot of peptides_per_1000aa. The plot area has been zoomed in. Now, we filter the proteins to 1% FDR. # 1% FDR filter at the protein level msnid &lt;- filter_msgf_data(msnid, level = &quot;accession&quot;, fdr.max = 0.01) show(msnid) ## MSnID object ## Working directory: &quot;.&quot; ## #Spectrum Files: 48 ## #PSMs: 464788 at 0.17 % FDR ## #peptides: 92176 at 0.34 % FDR ## #accessions: 15629 at 0.98 % FDR 1.1.6 Inference of Parsimonious Protein Set The situation when a certain peptide sequence matches multiple proteins adds complication to the downstream quantitative analysis, as it is not clear which protein this peptide is originating from. There are common ways for dealing with this. One is to simply retain uniquely-matching peptides and discard shared peptides (unique_only = TRUE). Alternatively, assign the shared peptides to the proteins with the most peptides (unique_only = FALSE). If there is a choice between multiple proteins with equal numbers of peptides, the shared peptides are assigned to the first protein according to alphanumeric order. It is an implementation of the greedy set cover algorithm. See ?MSnID::infer_parsimonious_accessions for more details. There is no single best approach for handling duplicate peptides. Some choose to not do anything and allow peptides to map to multiple proteins. With parsimonious inference, we make the assumption that proteins with more mapped peptides are more confidently identified, so we should assign shared peptides to them; however, this penalizes smaller proteins with fewer peptides. Think carefully before deciding which approach to use. Note: This step could be done prior to filtering at the accession level, but if peptides are assigned to a low-confidence protein, and that protein is removed during filtering, those peptides will be lost. Instead, it is better to filter to the set of confidently-identified proteins and then determine the parsimonious set. # Inference of parsimonious protein set msnid &lt;- infer_parsimonious_accessions(msnid, unique_only = FALSE) show(msnid) ## MSnID object ## Working directory: &quot;.&quot; ## #Spectrum Files: 48 ## #PSMs: 451568 at 0.16 % FDR ## #peptides: 90639 at 0.28 % FDR ## #accessions: 5247 at 1.1 % FDR Notice that the protein-level FDR increased slightly above the 1% threshold. In this case, the difference isn’t significant, so we can ignore it. Note: If the peptide or accession-level FDR increases significantly above 1% after inference of the parsimonious protein set, consider lowering the FDR cutoff (for example, to 0.9%) and redoing the previous processing steps. That is, start with the MSnID prior to any filtering and redo the FDR filtering steps. 1.1.7 Remove Decoy PSMs The final step in preparing the MS/MS identifications is to remove the decoy PSMs, as they were only needed for the FDR filters. We use the apply_filter function again and only keep entries where isDecoy is FALSE. # Remove Decoy PSMs msnid &lt;- apply_filter(msnid, &quot;!isDecoy&quot;) show(msnid) ## MSnID object ## Working directory: &quot;.&quot; ## #Spectrum Files: 48 ## #PSMs: 450857 at 0 % FDR ## #peptides: 90382 at 0 % FDR ## #accessions: 5191 at 0 % FDR After processing, we are left with 450,928 PSMs, 90,411 peptides, and 5,201 proteins. Table 1.1 shows the first 6 rows of the processed MS-GF+ output. Table 1.1: First 6 rows of the processed MS-GF+ results. Dataset ResultID Scan FragMethod SpecIndex Charge PrecursorMZ DelM DelM_PPM MH peptide Protein NTT DeNovoScore MSGFScore MSGFDB_SpecEValue Rank_MSGFDB_SpecEValue EValue QValue PepQValue IsotopeError accession calculatedMassToCharge chargeState experimentalMassToCharge isDecoy spectrumFile spectrumID pepSeq msmsScore absParentMassErrorPPM peptides_per_1000aa MoTrPAC_Pilot_TMT_W_S1_07_12Oct17_Elm_AQ-17-09-02 1862 27707 HCD 324 2 928.541 -0.001 -0.526 1856.075 R.AAAAAAAAAAAAAAGAAGK.E NP_113986.1 2 285 282 0 1 0 0.000 0.000 0 NP_113986.1 928.541 2 928.541 FALSE MoTrPAC_Pilot_TMT_W_S1_07_12Oct17_Elm_AQ-17-09-02 27707 AAAAAAAAAAAAAAGAAGK Inf 0.589 24.938 MoTrPAC_Pilot_TMT_W_S1_07_12Oct17_Elm_AQ-17-09-02 4192 27684 HCD 906 3 619.363 -0.002 -0.887 1856.075 R.AAAAAAAAAAAAAAGAAGK.E NP_113986.1 2 156 144 0 1 0 0.000 0.000 0 NP_113986.1 619.363 3 619.363 FALSE MoTrPAC_Pilot_TMT_W_S1_07_12Oct17_Elm_AQ-17-09-02 27684 AAAAAAAAAAAAAAGAAGK Inf 0.991 24.938 MoTrPAC_Pilot_TMT_W_S2_06_12Oct17_Elm_AQ-17-09-02 26263 27336 HCD 5187 3 619.363 0.000 0.197 1856.075 R.AAAAAAAAAAAAAAGAAGK.E NP_113986.1 2 118 85 0 1 0 0.000 0.000 0 NP_113986.1 619.363 3 619.363 FALSE MoTrPAC_Pilot_TMT_W_S2_06_12Oct17_Elm_AQ-17-09-02 27336 AAAAAAAAAAAAAAGAAGK Inf 0.091 24.938 MoTrPAC_Pilot_TMT_W_S2_07_12Oct17_Elm_AQ-17-09-02 1471 27096 HCD 415 3 619.363 -0.001 -0.591 1856.075 R.AAAAAAAAAAAAAAGAAGK.E NP_113986.1 2 157 156 0 1 0 0.000 0.000 0 NP_113986.1 619.363 3 619.363 FALSE MoTrPAC_Pilot_TMT_W_S2_07_12Oct17_Elm_AQ-17-09-02 27096 AAAAAAAAAAAAAAGAAGK Inf 0.684 24.938 MoTrPAC_Pilot_TMT_W_S2_05_12Oct17_Elm_AQ-17-09-02 28664 10441 HCD 4849 2 586.832 -0.001 -0.728 1172.659 R.AAAAADLANR.S NP_001007804.1 2 124 124 0 1 0 0.002 0.003 0 NP_001007804.1 586.833 2 586.832 FALSE MoTrPAC_Pilot_TMT_W_S2_05_12Oct17_Elm_AQ-17-09-02 10441 AAAAADLANR 2.480 0.746 34.755 MoTrPAC_Pilot_TMT_W_S1_24_12Oct17_Elm_AQ-17-09-02 41775 8033 HCD 7889 2 831.447 0.000 0.000 1661.886 G.AAAAAEAESGGGGGK.K NP_001128630.1 1 176 76 0 1 0 0.001 0.003 0 NP_001128630.1 831.447 2 831.447 FALSE MoTrPAC_Pilot_TMT_W_S1_24_12Oct17_Elm_AQ-17-09-02 8033 AAAAAEAESGGGGGK 2.583 0.106 579.815 References "],["prepare-reporter-ion-intensities.html", "1.2 Prepare Reporter Ion Intensities", " 1.2 Prepare Reporter Ion Intensities 1.2.1 Read MASIC Output MASIC is a tool for extracting ion intensities. With proper parameter settings, it can be used for extracting TMT (or iTRAQ) reporter ion intensities. In addition, it reports a number of other helpful metrics. Notably, the interference score at the precursor ion level and the signal-to-noise ratio (S/N) at the reporter ion level (computed by Thermo software). The interference score reflects the proportion of the ion population that was isolated for fragmentation that is due to the targeted ion. In other words, 1 - InterferenceScore is due to co-isolated species that have similar elution time and precursor ion m/z. The first step in the preparation of the reporter ion intensity data is to read the MASIC results. By default, the interference score is not included, so we need to set that argument to TRUE in order to filter the results after. Similar to the MS-GF+ results, we can read the MASIC results from a local folder with PlexedPiper::read_masic_data or from PNNL’s DMS with PNNL.DMS.utils::read_masic_data_from_DMS. ## Get MASIC results from local folder - not run # Get file path path_to_MASIC_results &lt;- &quot;path_to_folder_containing_necessary_files&quot; # Read MASIC results from path masic_data &lt;- read_masic_data(path_to_MASIC_results, interference_score = TRUE) ## Get MASIC results from DMS masic_data &lt;- read_masic_data_from_DMS(data_package_num, interference_score = TRUE) Normally, this would display progress bars in the console as the data is being fetched. However, the output was suppressed to save space. Table 1.2 shows the first 6 rows of the unfiltered masic_data. Table 1.2: First 6 rows of the unfiltered MASIC data. Dataset ScanNumber Ion_126.128 Ion_127.125 Ion_127.131 Ion_128.128 Ion_128.134 Ion_129.131 Ion_129.138 Ion_130.135 Ion_130.141 Ion_131.138 Ion_126.128_SignalToNoise Ion_127.125_SignalToNoise Ion_127.131_SignalToNoise Ion_128.128_SignalToNoise Ion_128.134_SignalToNoise Ion_129.131_SignalToNoise Ion_129.138_SignalToNoise Ion_130.135_SignalToNoise Ion_130.141_SignalToNoise Ion_131.138_SignalToNoise InterferenceScore MoTrPAC_Pilot_TMT_W_S1_01_12Oct17_Elm_AQ-17-09-02 2 70562.39 24864.62 17165.80 35625.00 92236.87 9640.23 8578.05 6996.69 11833.07 32281.34 71.47 25.17 17.38 36.04 93.32 9.75 8.67 7.07 11.96 32.71 0.996 MoTrPAC_Pilot_TMT_W_S1_01_12Oct17_Elm_AQ-17-09-02 3 23706.89 13559.32 5856.83 16322.71 34294.90 4853.11 7938.24 0.00 1465.03 18182.27 26.12 14.94 6.45 17.97 37.77 5.34 8.74 NA 1.61 19.93 0.993 MoTrPAC_Pilot_TMT_W_S1_01_12Oct17_Elm_AQ-17-09-02 4 12459.86 11785.91 10932.51 10653.32 12328.62 5959.86 9905.82 8387.04 11166.70 14053.40 12.40 11.75 10.90 10.64 12.31 5.96 9.91 8.40 11.18 14.13 1.000 MoTrPAC_Pilot_TMT_W_S1_01_12Oct17_Elm_AQ-17-09-02 5 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 NA NA NA NA NA NA NA NA NA NA 1.000 MoTrPAC_Pilot_TMT_W_S1_01_12Oct17_Elm_AQ-17-09-02 6 0.00 10998.67 0.00 21077.05 2725.50 0.00 0.00 0.00 0.00 6800.70 NA 9.19 NA 17.57 2.27 NA NA NA NA 5.66 1.000 MoTrPAC_Pilot_TMT_W_S1_01_12Oct17_Elm_AQ-17-09-02 8 6166.82 1371.27 2418.35 8087.76 5485.35 0.00 0.00 1543.48 1943.96 7436.60 6.92 1.54 2.71 9.04 6.13 NA NA 1.72 2.16 8.26 0.969 1.2.2 Filter MASIC Data The only other step in reporter ion intensity data preparation is to filter the results. Currently, we recommend keeping entries where at least 50% of the ion population is due to the targeted ion (interference score \\(\\geq\\) 0.5) and not filtering by S/N. To only reformat the data and not filter it, set both thresholds to 0. # Filter MASIC data masic_data &lt;- filter_masic_data(masic_data, interference_score_threshold = 0.5, s2n_threshold = 0) Table 1.2 shows the first 6 rows of the filtered masic_data. Table 1.3: First 6 rows of the filtered MASIC data. Dataset ScanNumber Ion_126.128 Ion_127.125 Ion_127.131 Ion_128.128 Ion_128.134 Ion_129.131 Ion_129.138 Ion_130.135 Ion_130.141 Ion_131.138 MoTrPAC_Pilot_TMT_W_S1_01_12Oct17_Elm_AQ-17-09-02 2 70562.39 24864.62 17165.80 35625.00 92236.87 9640.23 8578.05 6996.69 11833.07 32281.34 MoTrPAC_Pilot_TMT_W_S1_01_12Oct17_Elm_AQ-17-09-02 3 23706.89 13559.32 5856.83 16322.71 34294.90 4853.11 7938.24 0.00 1465.03 18182.27 MoTrPAC_Pilot_TMT_W_S1_01_12Oct17_Elm_AQ-17-09-02 4 12459.86 11785.91 10932.51 10653.32 12328.62 5959.86 9905.82 8387.04 11166.70 14053.40 MoTrPAC_Pilot_TMT_W_S1_01_12Oct17_Elm_AQ-17-09-02 5 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 MoTrPAC_Pilot_TMT_W_S1_01_12Oct17_Elm_AQ-17-09-02 6 0.00 10998.67 0.00 21077.05 2725.50 0.00 0.00 0.00 0.00 6800.70 MoTrPAC_Pilot_TMT_W_S1_01_12Oct17_Elm_AQ-17-09-02 8 6166.82 1371.27 2418.35 8087.76 5485.35 0.00 0.00 1543.48 1943.96 7436.60 Lastly, we will save the processed MSnID and MASIC data to an .RData file with compression. This is useful in case we want to create different cross-tabs with new study design tables later on. # Save processed MSnID and MASIC data save(msnid, masic_data, file = &quot;data/3442_processed_msnid_and_masic.RData&quot;, compress = TRUE) "],["fetch-study-design-tables.html", "1.3 Create Study Design Tables", " 1.3 Create Study Design Tables To convert from PSMs and reporter ion intensities to meaningful quantitative data, it is necessary to specify the study design. The entire study design is captured by three tables: fractions, samples, and references. With newly processed data, these typically do not exist, and must be created. The next sections show how to create these tables in R. NOTE: simple study designs can be created in Excel and read in with readxl::read_excel, though R is the better choice when dealing with many samples. 1.3.1 Fractions The fractions table consists of two columns: Dataset and PlexID. The Dataset column contains all of the unique datasets that are common to msnid and masic_data. Sometimes, entire datasets may be removed during the FDR filtering steps, so that is why we use the unique intersection of datasets. The PlexID column contains the plex ID associated with each dataset, and is typically a letter followed by a number (“S1”, “S2”, etc.). A plex is a set of samples that are processed together (under the same conditions). Usually, we can extract the plex ID from the datasets. In this case, the plex ID always comes after “_W_”, so we can use a regular expression (use help(topic = regex, package = base) to learn more). The regular expression below says to capture an “S” followed by a single digit that appears after “_W_” and before an underscore. The plex ID is always included in the dataset names, but the format of the names will be different. # Create fractions table datasets &lt;- unique(intersect(msnid$Dataset, masic_data$Dataset)) fractions &lt;- data.frame(Dataset = datasets) %&gt;% mutate(PlexID = gsub(&quot;.*_W_(S\\\\d{1})_.*&quot;, &quot;\\\\1&quot;, Dataset)) Table 1.4: Fractions Dataset PlexID MoTrPAC_Pilot_TMT_W_S1_07_12Oct17_Elm_AQ-17-09-02 S1 MoTrPAC_Pilot_TMT_W_S2_06_12Oct17_Elm_AQ-17-09-02 S2 MoTrPAC_Pilot_TMT_W_S2_07_12Oct17_Elm_AQ-17-09-02 S2 MoTrPAC_Pilot_TMT_W_S2_05_12Oct17_Elm_AQ-17-09-02 S2 MoTrPAC_Pilot_TMT_W_S1_24_12Oct17_Elm_AQ-17-09-02 S1 MoTrPAC_Pilot_TMT_W_S2_08_12Oct17_Elm_AQ-17-09-02 S2 MoTrPAC_Pilot_TMT_W_S1_16_12Oct17_Elm_AQ-17-09-02 S1 MoTrPAC_Pilot_TMT_W_S2_16_12Oct17_Elm_AQ-17-09-02 S2 MoTrPAC_Pilot_TMT_W_S2_23_12Oct17_Elm_AQ-17-09-02 S2 MoTrPAC_Pilot_TMT_W_S1_15_12Oct17_Elm_AQ-17-09-02 S1 MoTrPAC_Pilot_TMT_W_S2_09_12Oct17_Elm_AQ-17-09-02 S2 MoTrPAC_Pilot_TMT_W_S1_17_12Oct17_Elm_AQ-17-09-02 S1 MoTrPAC_Pilot_TMT_W_S1_08_12Oct17_Elm_AQ-17-09-02 S1 MoTrPAC_Pilot_TMT_W_S1_23_12Oct17_Elm_AQ-17-09-02 S1 MoTrPAC_Pilot_TMT_W_S2_22_12Oct17_Elm_AQ-17-09-02 S2 MoTrPAC_Pilot_TMT_W_S1_01_12Oct17_Elm_AQ-17-09-02 S1 MoTrPAC_Pilot_TMT_W_S2_24_12Oct17_Elm_AQ-17-09-02 S2 MoTrPAC_Pilot_TMT_W_S1_05_12Oct17_Elm_AQ-17-09-02 S1 MoTrPAC_Pilot_TMT_W_S1_04_12Oct17_Elm_AQ-17-09-02 S1 MoTrPAC_Pilot_TMT_W_S2_04_12Oct17_Elm_AQ-17-09-02 S2 MoTrPAC_Pilot_TMT_W_S1_02_12Oct17_Elm_AQ-17-09-02 S1 MoTrPAC_Pilot_TMT_W_S2_01_12Oct17_Elm_AQ-17-09-02 S2 MoTrPAC_Pilot_TMT_W_S1_13_12Oct17_Elm_AQ-17-09-02 S1 MoTrPAC_Pilot_TMT_W_S2_12_12Oct17_Elm_AQ-17-09-02 S2 MoTrPAC_Pilot_TMT_W_S1_03_12Oct17_Elm_AQ-17-09-02 S1 MoTrPAC_Pilot_TMT_W_S2_03_12Oct17_Elm_AQ-17-09-02 S2 MoTrPAC_Pilot_TMT_W_S1_18_12Oct17_Elm_AQ-17-09-02 S1 MoTrPAC_Pilot_TMT_W_S2_18_12Oct17_Elm_AQ-17-09-02 S2 MoTrPAC_Pilot_TMT_W_S1_20_12Oct17_Elm_AQ-17-09-02 S1 MoTrPAC_Pilot_TMT_W_S1_06_12Oct17_Elm_AQ-17-09-02 S1 MoTrPAC_Pilot_TMT_W_S1_21_12Oct17_Elm_AQ-17-09-02 S1 MoTrPAC_Pilot_TMT_W_S1_10_12Oct17_Elm_AQ-17-09-02 S1 MoTrPAC_Pilot_TMT_W_S1_19_12Oct17_Elm_AQ-17-09-02 S1 MoTrPAC_Pilot_TMT_W_S2_15_12Oct17_Elm_AQ-17-09-02 S2 MoTrPAC_Pilot_TMT_W_S2_17_12Oct17_Elm_AQ-17-09-02 S2 MoTrPAC_Pilot_TMT_W_S1_12_12Oct17_Elm_AQ-17-09-02 S1 MoTrPAC_Pilot_TMT_W_S1_14_12Oct17_Elm_AQ-17-09-02 S1 MoTrPAC_Pilot_TMT_W_S2_13_12Oct17_Elm_AQ-17-09-02 S2 MoTrPAC_Pilot_TMT_W_S2_14_12Oct17_Elm_AQ-17-09-02 S2 MoTrPAC_Pilot_TMT_W_S1_09_12Oct17_Elm_AQ-17-09-02 S1 MoTrPAC_Pilot_TMT_W_S1_11_12Oct17_Elm_AQ-17-09-02 S1 MoTrPAC_Pilot_TMT_W_S1_22_12Oct17_Elm_AQ-17-09-02 S1 MoTrPAC_Pilot_TMT_W_S2_10_12Oct17_Elm_AQ-17-09-02 S2 MoTrPAC_Pilot_TMT_W_S2_11_12Oct17_Elm_AQ-17-09-02 S2 MoTrPAC_Pilot_TMT_W_S2_19_12Oct17_Elm_AQ-17-09-02 S2 MoTrPAC_Pilot_TMT_W_S2_20_12Oct17_Elm_AQ-17-09-02 S2 MoTrPAC_Pilot_TMT_W_S2_21_12Oct17_Elm_AQ-17-09-02 S2 MoTrPAC_Pilot_TMT_W_S2_02_12Oct17_Elm_AQ-17-09-02 S2 1.3.2 Samples The samples table contains columns PlexID, QuantBlock, ReporterName, ReporterAlias, and MeasurementName. PlexID must be the same as the PlexID in the fractions table. ReporterName is the reporter ion name (“126”, “127N”, “127C”, etc.). ReporterAlias is used for defining the reference channel(s). MeasurementName determines the column names for the final cross-tab, and must be unique and begin with a letter. If any values of ReporterAlias are “ref”, the corresponding MeasurementName should be NA. NA measurement names will not appear as columns in the final cross-tab. QuantBlock defines the sub-plex. In a typical TMT experiment, QuantBlock is always 1. In case of 5 pairwise comparisons within TMT10, there will be 5 QuantBlocks (1-5) potentially with a reference for each QuantBlock. For this experiment, TMT10 was used as the basis for two plexes, and channel 131 is the reference, so we set ReporterAlias to “ref” and MeasurementName to NA when ReporterName is \"131\". This will divide the intensities of each channel by their associated reference and make the reference channel absent from the quantitative cross-tab. In cases where reporter ion intensities are not normalized by a reference channel (reference = 1) or they are normalized by the average of select channels, do not set any ReporterAlias to “ref” or MeasurementName to NA. # Create samples table samples &lt;- reporter_converter$tmt10 %&gt;% dplyr::select(ReporterName) %&gt;% # only keep ReporterName column dplyr::slice(rep(1:n(), times = 2)) %&gt;% # Copy TMT10 table twice (2 plexes) # Create PlexID and QuantBlock columns. # Plex S1 goes with first 10 rows, plex S2 with last 10 mutate(PlexID = paste0(&quot;S&quot;, rep(1:2, each = 10)), QuantBlock = 1) %&gt;% group_by(PlexID) %&gt;% # Within each of the two PlexID groups, create unique reporter aliases # and measurement names. ReporterAlias is &quot;ref&quot; for channel 131, # and MeasurementName is NA so it is not included in the cross-tab. mutate(ReporterAlias = paste(PlexID, 1:n(), sep = &quot;_&quot;), ReporterAlias = ifelse(ReporterName == &quot;131&quot;, &quot;ref&quot;, ReporterAlias), MeasurementName = ifelse(ReporterName == &quot;131&quot;, NA, ReporterAlias)) %&gt;% ungroup() # stop grouping by PlexID Table 1.5: Samples ReporterName PlexID QuantBlock ReporterAlias MeasurementName 126 S1 1 S1_1 S1_1 127N S1 1 S1_2 S1_2 127C S1 1 S1_3 S1_3 128N S1 1 S1_4 S1_4 128C S1 1 S1_5 S1_5 129N S1 1 S1_6 S1_6 129C S1 1 S1_7 S1_7 130N S1 1 S1_8 S1_8 130C S1 1 S1_9 S1_9 131 S1 1 ref NA 126 S2 1 S2_1 S2_1 127N S2 1 S2_2 S2_2 127C S2 1 S2_3 S2_3 128N S2 1 S2_4 S2_4 128C S2 1 S2_5 S2_5 129N S2 1 S2_6 S2_6 129C S2 1 S2_7 S2_7 130N S2 1 S2_8 S2_8 130C S2 1 S2_9 S2_9 131 S2 1 ref NA Table 1.5 shows the samples table. 1.3.3 References The reference can be a certain channel, the geometric average of channels, 1 (no reference), or an R expression that evaluates to a vector. The general form is an expression with ReporterAlias names as variables. It is evaluated for each PlexID/QuantBlock combination and applied to divide reporter ion intensities within corresponding PlexID/QuantBlock. A reference is used to convert raw intensities to relative intensities. # Create references table references &lt;- samples %&gt;% filter(ReporterAlias == &quot;ref&quot;) %&gt;% # Select required columns and rename ReporterAlias to Reference select(PlexID, QuantBlock, Reference = ReporterAlias) Table 1.6: References PlexID QuantBlock Reference S1 1 ref S2 1 ref Table 1.6 shows the references table. The code to use the geometric average instead of a single channel as the reference is shown below. The geometric average is the product of the reporter ion channels to the power of (1/number of channels). For each PlexID group, collapse the vector of reporter ion names with *, surround them in parentheses, and raise to the power of (1/number of channels). Note: If the reference is not a particular channel that will be excluded from the final results, there should not be any ReporterAlias that are “ref” or MeasurementName that are NA. ## Example of how to use the geometric average as reference - not run references &lt;- samples %&gt;% group_by(PlexID, QuantBlock) %&gt;% summarise(Reference = sprintf(&quot;(%s)^(1/%d)&quot;, paste(ReporterAlias, collapse = &quot;*&quot;), n()), .groups = &quot;keep&quot;) ## Example of how to set the reference to 1 - not run references &lt;- samples %&gt;% distinct(PlexID, QuantBlock) %&gt;% mutate(Reference = 1) Now that we have the three study design tables, we should save them. # Save study design tables with write.table write.table(fractions, file = &quot;data/3442_fractions.txt&quot;, sep = &quot;\\t&quot;, quote = FALSE, row.names = FALSE) write.table(samples, file = &quot;data/3442_samples.txt&quot;, sep = &quot;\\t&quot;, quote = FALSE, row.names = FALSE) write.table(references, file = &quot;data/3442_references.txt&quot;, sep = &quot;\\t&quot;, quote = FALSE, row.names = FALSE) Once the study design tables have been saved to text files, it is good practice to make them available to others. To do so, navigate to the Share Path provided in the DMS Data Package Detail Report (shown in Figure 1.7), and copy the three study design files to this location. This allows them to be accessed by others with the get_study_design_by_dataset_package function in the future. Figure 1.7: Location of the Share Path used to add the study design tables. "],["global-quant-crosstab.html", "1.4 Create Quantitative Cross-tab", " 1.4 Create Quantitative Cross-tab This is the step where MS/MS IDs and reporter ions are linked together and aggregated to the peptide or accession (i.e. protein) level. To retain protein IDs while aggregating to peptide level, set aggregation_level &lt;- c(\"accession\",\"peptide\"). The aggregation level can be any column or combination of columns in psms(msnid). If specified by the study design tables, the intensities are converted to relative intensities by dividing by a reference. Then, they are log\\(_2\\)-transformed. # Create protein-level cross-tab by aggregating to accession level crosstab &lt;- create_crosstab(msnid = msnid, reporter_intensities = masic_data, aggregation_level = &quot;accession&quot;, fractions = fractions, samples = samples, references = references) Table 1.7: First 6 rows of the cross-tab. S1_1 S1_2 S1_3 S1_4 S1_5 S1_6 S1_7 S1_8 S1_9 S2_1 S2_2 S2_3 S2_4 S2_5 S2_6 S2_7 S2_8 S2_9 AP_004893.1 0.1419768 0.1653552 0.7628195 0.9453172 0.8662554 -1.9294467 -0.6460065 -1.2831873 -0.4321433 -1.0271227 0.4883309 -0.9390945 -0.7029685 -1.7148628 -0.1912097 -0.8794712 -0.2440478 0.3964607 AP_004894.1 0.7947114 -0.3151990 -0.0913574 0.1974134 0.3033858 -0.1750536 -0.3527197 -1.1762004 -0.6438817 -0.5124954 -0.4428327 -0.2364175 -0.6711809 -1.3730408 -0.7462995 -1.3515366 -0.2227493 -0.8338103 AP_004895.1 0.2078433 -0.6089756 -0.2867209 -0.3840271 -0.1162062 -0.6908468 -1.1240967 -0.7140383 -0.6652575 0.2843676 -0.1312555 -0.1477038 -0.4352950 -0.6371609 -0.6150788 -0.6819180 -0.1602120 -0.3978979 AP_004896.1 -0.1494849 -0.7314368 -0.3664339 -0.5352280 -0.1742391 -1.0372327 -1.2945071 -0.8299749 -0.7060783 0.1939540 -0.1688422 -0.2274358 -0.4222698 -0.5251264 -0.6741064 -0.6543311 -0.0441485 -0.3994149 AP_004898.1 0.0362964 0.4252227 0.7497227 1.1580326 0.4913660 -0.3640632 0.1211536 -0.8291744 -0.3019505 -0.8407749 -0.4130732 -0.2796091 -0.9449498 -1.5747761 -0.1774225 -1.8439756 -0.4175363 -1.1083199 AP_004899.1 0.7140968 -0.3732752 -0.1781542 -0.0615626 0.3494902 -0.8550940 -2.1679002 -1.4519278 -0.9026145 -0.3158081 -0.4644758 -0.4056811 -0.9023044 -0.2805080 -0.8052899 -1.0482424 -0.3959923 -0.6675429 Now that we have the cross-tab, we should save it. # Save cross-tab write.table(crosstab, file = &quot;data/3442_global_crosstab.txt&quot;, sep = &quot;\\t&quot;, quote = FALSE, row.names = TRUE) We will also save the proteins (row names) of this cross-tab in order to demonstrate prioritized inference later on. # Save global proteins global_proteins &lt;- rownames(crosstab) save(global_proteins, file = &quot;data/3442_global_proteins.RData&quot;) "],["global-msnset.html", "1.5 Create MSnSet", " 1.5 Create MSnSet The create_msnset function can be used to easily create an MSnSet from the cross-tab and samples tables. More details about MSnSets will be added in a separate section at a later date. For now, read the documentation with help(\"MSnSet\") or ?MSnSet. # Create MSnSet m1 &lt;- create_msnset(crosstab = crosstab, samples = samples) m1 ## MSnSet (storageMode: lockedEnvironment) ## assayData: 5173 features, 18 samples ## element names: exprs ## protocolData: none ## phenoData ## sampleNames: S1_1 S1_2 ... S2_9 (18 total) ## varLabels: ReporterName PlexID ... MeasurementName (5 total) ## varMetadata: labelDescription ## featureData: none ## experimentData: use &#39;experimentData(object)&#39; ## Annotation: ## - - - Processing information - - - ## MSnbase version: 2.22.0 # Save global MSnSet save(m1, file = &quot;data/global_msnset.RData&quot;, compress = TRUE) "],["iso-phospho.html", "Section 2 Isobaric Quantification: Phosphoproteomics", " Section 2 Isobaric Quantification: Phosphoproteomics This pipeline shows how to process phosphoproteomics TMT data with PlexedPiper, though it can be used for any type of post-translational modification (PTM) TMT data. We will use data package 3626, which is “PlexedPiperTestData phospho”. In addition to PlexedPiper, we will also need MSnID (the basis for PlexedPiper), PNNL.DMS.utils to interface with PNNL’s DMS, and Biostrings to create an AAStringSet object from a FASTA file. Since a lot of these steps are the same as in Section 1, a lot of the details will be omitted. ## Install missing packages if (!require(&quot;remotes&quot;, quietly = T)) install.packages(&quot;remotes&quot;) git_packages &lt;- c(&quot;MSnID@pnnl-master&quot;, &quot;PlexedPiper&quot;, &quot;PNNL.DMS.utils&quot;) for (pkg_i in git_packages) { if (!require(sub(&quot;@.*&quot;, &quot;&quot;, pkg_i), quietly = T, character.only = T)) remotes::install_github(file.path(&quot;PNNL-Comp-Mass-Spec&quot;, pkg_i)) } if (!requireNamespace(&quot;BiocManager&quot;, quietly = T)) install.packages(&quot;BiocManager&quot;) if (!require(&quot;Biostrings&quot;, quietly = T)) BiocManager::install(&quot;Biostrings&quot;) ## ------------------------ library(MSnID) library(PlexedPiper) library(PNNL.DMS.utils) library(Biostrings) "],["prepare-msms-identifications-1.html", "2.1 Prepare MS/MS Identifications", " 2.1 Prepare MS/MS Identifications 2.1.1 Read MS-GF+ Data # Read MS-GF+ data data_package_num &lt;- 3626 # phospho msnid &lt;- read_msgf_data_from_DMS(data_package_num) show(msnid) ## MSnID object ## Working directory: &quot;.&quot; ## #Spectrum Files: 23 ## #PSMs: 612667 at 55 % FDR ## #peptides: 396540 at 75 % FDR ## #accessions: 121521 at 98 % FDR 2.1.2 Correct Isotope Selection Error # Correct for isotope selection error msnid &lt;- correct_peak_selection(msnid) 2.1.3 Remove Unmodified Peptides Generally, we will remove unmodified peptides before any sort of filtering steps; however, unmodified peptides will be removed automatically in Section 2.1.9, so this step can be skipped if we need to tally the number of modified and unmodified peptides toward the end of processing. In this case, the phosphorylation of an amino acid is marked by a * appearing next in the sequence. We can filter out peptides that do not contain this symbol with apply_filter. In regular expressions, the * is a special character called a metacharacter that must be escaped with backslashes, and the backslashes must also be escaped, since they are enclosed within a nested string (\"''\"). For non-metacharacters, it is not necessary to include the backslashes. # Remove non-phosphorylated peptides # (peptides that do not contain a *) msnid &lt;- apply_filter(msnid, &quot;grepl(&#39;\\\\\\\\*&#39;, peptide)&quot;) show(msnid) ## MSnID object ## Working directory: &quot;.&quot; ## #Spectrum Files: 23 ## #PSMs: 537749 at 57 % FDR ## #peptides: 353634 at 76 % FDR ## #accessions: 118817 at 98 % FDR 2.1.4 Remove Contaminants # Remove contaminants msnid &lt;- apply_filter(msnid, &quot;!grepl(&#39;Contaminant&#39;, accession)&quot;) show(msnid) ## MSnID object ## Working directory: &quot;.&quot; ## #Spectrum Files: 23 ## #PSMs: 537572 at 57 % FDR ## #peptides: 353489 at 76 % FDR ## #accessions: 118797 at 98 % FDR 2.1.5 Improve Phosphosite Localization Phospho datasets involve Ascore jobs for improving phosphosite localization. There should be one AScore job per data package. If the Ascore job does not exist, see AScore Job Creation for how to set it up. The fetched object is a data.frame that links datasets, scans and original PTM localization to newly suggested locations. Importantly, it contains AScore column that “measures the probability of correct phosphorylation site localization” (Beausoleil et al., 2006). AScore &gt; 17 is considered confident. # Filter PTMs by Ascore - only for phospho data ascore &lt;- get_AScore_results(data_package_num) msnid &lt;- best_PTM_location_by_ascore(msnid, ascore) 2.1.6 MS/MS ID Filter: Peptide Level # 1% FDR filter at the peptide level msnid &lt;- filter_msgf_data(msnid, level = &quot;peptide&quot;, fdr.max = 0.01) show(msnid) ## MSnID object ## Working directory: &quot;.&quot; ## #Spectrum Files: 23 ## #PSMs: 77741 at 0.51 % FDR ## #peptides: 23118 at 1 % FDR ## #accessions: 15964 at 4.8 % FDR 2.1.7 MS/MS ID Filter: Protein Level This step is unnecessary for PTM data, since the cross-tab is not created at the protein level, so it is skipped. 2.1.8 Inference of Parsimonious Protein Set If a protein was detected in the global proteomics results, we may be more confident that it will appear in the PTM results. We can perform prioritized inference of the protein set to ensure that, if a protein is reported in the global cross-tab, and it is present in the PTM MSnID after filtering, it will be included in the final PTM MSnID. We set the proteins from the global cross-tab as the prior. By default, peptides are allowed to match multiple proteins in the prior. If duplicates are not allowed, we can set the refine_prior argument to TRUE. # Proteins from global proteomics cross-tab load(&quot;./data/3442_global_proteins.RData&quot;) # Prioritized inference of parsimonious protein set msnid &lt;- infer_parsimonious_accessions(msnid, unique_only = FALSE, prior = global_proteins, refine_prior = FALSE) show(msnid) ## MSnID object ## Working directory: &quot;.&quot; ## #Spectrum Files: 23 ## #PSMs: 77738 at 0.51 % FDR ## #peptides: 23117 at 0.99 % FDR ## #accessions: 4419 at 4.8 % FDR 2.1.9 Map Sites to Protein Sequences MSnID::map_mod_sites creates a number of columns describing mapping of the modification sites onto the protein sequences. The most important for the user is SiteID. names(fst) must match accessions(msnid); usually, we will have to modify names to remove everything after the first word. # Create AAStringSet path_to_FASTA &lt;- path_to_FASTA_used_by_DMS(data_package_num) fst &lt;- readAAStringSet(path_to_FASTA) # Remove contaminants fst &lt;- fst[!grepl(&quot;Contaminant&quot;, names(fst)), ] # First 6 names head(names(fst)) ## [1] &quot;NP_783171.2 cathepsin R precursor [Rattus norvegicus]&quot; ## [2] &quot;NP_001101862.2 zinc finger protein ZIC 2 [Rattus norvegicus]&quot; ## [3] &quot;NP_113721.4 UDP-glucuronosyltransferase 2B2 precursor [Rattus norvegicus]&quot; ## [4] &quot;NP_714948.1 Ly-49 stimulatory receptor 3 [Rattus norvegicus]&quot; ## [5] &quot;NP_001000704.1 olfactory receptor Olr931 [Rattus norvegicus]&quot; ## [6] &quot;NP_001000638.1 olfactory receptor Olr652 [Rattus norvegicus]&quot; # Modify names to match accessions(msnid) # Remove any space followed by any number of characters names(fst) &lt;- sub(&quot; .*&quot;, &quot;&quot;, names(fst)) # First 6 names head(names(fst)) ## [1] &quot;NP_783171.2&quot; &quot;NP_001101862.2&quot; &quot;NP_113721.4&quot; &quot;NP_714948.1&quot; ## [5] &quot;NP_001000704.1&quot; &quot;NP_001000638.1&quot; The names are in the proper format, so we can continue with the main mapping call. This will also remove any unmodified peptides, if Section 2.1.3 was skipped. # Main mapping call msnid &lt;- map_mod_sites(object = msnid, fasta = fst, accession_col = &quot;accession&quot;, peptide_mod_col = &quot;peptide&quot;, mod_char = &quot;*&quot;, # asterisk for phosphorylation site_delimiter = &quot;;&quot;) # semicolon between multiple sites Table 2.1 shows the first 6 rows of the processed MS-GF+ output. Table 2.1: First 6 rows of the processed MS-GF+ results. Dataset ResultID Scan FragMethod SpecIndex Charge PrecursorMZ DelM DelM_PPM MH OriginalPeptide Protein NTT DeNovoScore MSGFScore MSGFDB_SpecEValue Rank_MSGFDB_SpecEValue EValue QValue PepQValue IsotopeError accession calculatedMassToCharge chargeState experimentalMassToCharge isDecoy spectrumFile spectrumID pepSeq peptide maxAScore msmsScore absParentMassErrorPPM First_AA Last_AA First_AA_First Last_AA_First ProtLen ModShift ModAAs SiteLoc Site SiteCollapsed SiteCollapsedFirst SiteID MoTrPAC_Pilot_TMT_P_S1_06_DIL_28Oct17_Elm_AQ-17-10-03 12697 27321 HCD 2256 3 1045.124 0.003 0.858 3131.346 A.AAAAAGDS*DS*WDADTFSMEDPVRK.V NP_001071138.1 1 146 58 0 1 0 0 0 2 NP_001071138.1 1044.454 3 1044.455 FALSE MoTrPAC_Pilot_TMT_P_S1_06_DIL_28Oct17_Elm_AQ-17-10-03 27321 AAAAAGDSDSWDADTFSMEDPVRK A.AAAAAGDSDS*WDADT*FSMEDPVRK.V 0.000 Inf 1.057 5 28 5 28 259 9, 14 S, T 14, 19 S14, T19 S14,T19 S14,T19 NP_001071138.1-S14;T19 MoTrPAC_Pilot_TMT_P_S1_07_DIL_28Oct17_Elm_AQ-17-10-03 875 23519 HCD 264 3 952.144 0.004 1.538 2854.412 R.AAAASAAEAGIAT*PGTEDSDDALLK.M XP_006232986.1 2 165 129 0 1 0 0 0 0 XP_006232986.1 952.142 3 952.144 FALSE MoTrPAC_Pilot_TMT_P_S1_07_DIL_28Oct17_Elm_AQ-17-10-03 23519 AAAASAAEAGIATPGTEDSDDALLK R.AAAASAAEAGIAT*PGTEDSDDALLK.M 52.349 Inf 1.625 238 262 238 262 377 12 T 250 T250 T250 T250 XP_006232986.1-T250 MoTrPAC_Pilot_TMT_P_S1_07_DIL_28Oct17_Elm_AQ-17-10-03 12873 23508 HCD 2213 4 714.360 0.007 2.392 2854.412 R.AAAASAAEAGIAT*PGTEDSDDALLK.M XP_006232986.1 2 122 81 0 1 0 0 0 0 XP_006232986.1 714.358 4 714.360 FALSE MoTrPAC_Pilot_TMT_P_S1_07_DIL_28Oct17_Elm_AQ-17-10-03 23508 AAAASAAEAGIATPGTEDSDDALLK R.AAAASAAEAGIAT*PGTEDSDDALLK.M 17.480 Inf 2.472 238 262 238 262 377 12 T 250 T250 T250 T250 XP_006232986.1-T250 MoTrPAC_Pilot_TMT_P_S2_07_3Nov17_Elm_AQ-17-10-03 1793 23803 HCD 349 3 952.472 -0.015 -5.362 2854.412 R.AAAASAAEAGIAT*PGTEDSDDALLK.M XP_006232986.1 2 146 116 0 1 0 0 0 1 XP_006232986.1 952.142 3 952.137 FALSE MoTrPAC_Pilot_TMT_P_S2_07_3Nov17_Elm_AQ-17-10-03 23803 AAAASAAEAGIATPGTEDSDDALLK R.AAAASAAEAGIAT*PGTEDSDDALLK.M 52.349 Inf 5.277 238 262 238 262 377 12 T 250 T250 T250 T250 XP_006232986.1-T250 MoTrPAC_Pilot_TMT_P_S2_07_3Nov17_Elm_AQ-17-10-03 2731 23697 HCD 502 4 714.610 0.002 0.706 2854.412 R.AAAASAAEAGIAT*PGTEDSDDALLK.M XP_006232986.1 2 135 104 0 1 0 0 0 1 XP_006232986.1 714.358 4 714.359 FALSE MoTrPAC_Pilot_TMT_P_S2_07_3Nov17_Elm_AQ-17-10-03 23697 AAAASAAEAGIATPGTEDSDDALLK R.AAAASAAEAGIAT*PGTEDSDDALLK.M 26.295 Inf 0.780 238 262 238 262 377 12 T 250 T250 T250 T250 XP_006232986.1-T250 MoTrPAC_Pilot_TMT_P_S1_07_DIL_28Oct17_Elm_AQ-17-10-03 4877 21265 HCD 935 4 800.403 0.006 1.871 3196.577 R.AAAASAAEAGIAT*PGTEGERDSDDALLK.M NP_112621.1 2 194 114 0 1 0 0 0 2 NP_112621.1 799.900 4 799.901 FALSE MoTrPAC_Pilot_TMT_P_S1_07_DIL_28Oct17_Elm_AQ-17-10-03 21265 AAAASAAEAGIATPGTEGERDSDDALLK R.AAAASAAEAGIATPGT*EGERDSDDALLK.M 6.213 Inf 1.902 238 265 238 265 380 15 T 253 T253 T253 T253 NP_112621.1-T253 2.1.10 Remove Decoy PSMs # Remove Decoy PSMs msnid &lt;- apply_filter(msnid, &quot;!isDecoy&quot;) show(msnid) ## MSnID object ## Working directory: &quot;.&quot; ## #Spectrum Files: 23 ## #PSMs: 77347 at 0 % FDR ## #peptides: 22890 at 0 % FDR ## #accessions: 4216 at 0 % FDR References "],["prepare-reporter-ion-intensities-1.html", "2.2 Prepare Reporter Ion Intensities", " 2.2 Prepare Reporter Ion Intensities 2.2.1 Read MASIC Output # Read MASIC data masic_data &lt;- read_masic_data_from_DMS(data_package_num, interference_score = TRUE) 2.2.2 Filter MASIC Data # Filter MASIC data masic_data &lt;- filter_masic_data(masic_data, interference_score_threshold = 0.5, s2n_threshold = 0) "],["create-study-design-tables.html", "2.3 Create Study Design Tables", " 2.3 Create Study Design Tables Aside from the fractions table, the other study design tables can be the same as those created for the global proteomics data. This is because the datasets are different. The study design tables have been added to the data package (end of Section 1.3.3), so we can use get_study_design_by_dataset_package. # Create fractions table datasets &lt;- unique(intersect(msnid$Dataset, masic_data$Dataset)) fractions &lt;- data.frame(Dataset = datasets) %&gt;% mutate(PlexID = gsub(&quot;.*_P_(S\\\\d{1})_.*&quot;, &quot;\\\\1&quot;, Dataset)) # Use global samples and references tables study_design &lt;- get_study_design_by_dataset_package(3442) samples &lt;- study_design$samples references &lt;- study_design$references # Save phospho fractions table write.table(fractions, file = &quot;data/3626_fractions.txt&quot;, sep = &quot;\\t&quot;, quote = FALSE, row.names = FALSE) "],["create-quantitative-cross-tab.html", "2.4 Create Quantitative Cross-tab", " 2.4 Create Quantitative Cross-tab # Create cross-tab - aggregate to SiteID level crosstab &lt;- create_crosstab(msnid = msnid, reporter_intensities = masic_data, aggregation_level = &quot;SiteID&quot;, fractions = fractions, samples = samples, references = references) Table 2.2: First 6 rows of the phospho quantitative cross-tab. S1_1 S1_2 S1_3 S1_4 S1_5 S1_6 S1_7 S1_8 S1_9 S2_1 S2_2 S2_3 S2_4 S2_5 S2_6 S2_7 S2_8 S2_9 NP_001001064.1-Y129 NA NA NA NA NA NA NA NA NA 0.1594274 0.1932351 -0.6587720 -0.4461276 -0.6370354 -0.2976259 -1.0408865 -0.1385762 -0.7301538 NP_001001512.2-S241 -0.5441083 -0.5540885 -0.0291611 -0.5675833 -0.1812456 -0.803056 -0.0427948 -1.0398773 -0.5236890 NA NA NA NA NA NA NA NA NA NP_001001512.2-S242 -0.2806018 -0.3923442 -0.2939827 -0.6512914 -0.3242804 -1.210593 -0.4914234 -0.8869142 -0.6421375 -0.3079991 -0.4801256 -0.8072458 -0.7588038 -0.4458455 -0.6640721 -1.3958746 -0.3091972 -0.7046127 NP_001001512.2-S699 NA NA NA NA NA NA NA NA NA -0.7930334 -0.4608541 -1.2173509 -0.8004630 -1.2596689 -0.4918316 -0.8584401 0.2867235 -0.2745069 NP_001001512.2-S746 NA NA NA NA NA NA NA NA NA -1.4611181 -1.6828088 -2.2975481 -1.8632844 -2.3039510 -1.5981389 NA -0.4736739 -2.4732843 NP_001001512.2-S748 -1.4431878 -1.3790462 -1.5034294 0.0053341 -2.1869459 -1.879176 -0.5153039 -1.7646633 -1.6533568 0.3139811 -0.8132341 -0.6805752 0.0127816 -1.7933771 0.2266855 0.2726023 0.9332038 0.5058189 # Save cross-tab write.table(crosstab, file = &quot;data/3662_phospho_crosstab.txt&quot;, sep = &quot;\\t&quot;, quote = FALSE, row.names = TRUE) "],["phospho-msnset.html", "2.5 Create MSnSet", " 2.5 Create MSnSet # Create MSnSet m &lt;- create_msnset(crosstab = crosstab, samples = samples) m ## MSnSet (storageMode: lockedEnvironment) ## assayData: 26047 features, 18 samples ## element names: exprs ## protocolData: none ## phenoData ## sampleNames: S1_1 S1_2 ... S2_9 (18 total) ## varLabels: ReporterName PlexID ... MeasurementName (5 total) ## varMetadata: labelDescription ## featureData: none ## experimentData: use &#39;experimentData(object)&#39; ## Annotation: ## - - - Processing information - - - ## MSnbase version: 2.22.0 # Save phospho MSnSet save(m, file = &quot;data/phospho_msnset.RData&quot;, compress = TRUE) "],["spectral-counting.html", "Section 3 Spectral Counting", " Section 3 Spectral Counting This is a generic spectral counting script for MS-GF+ Human/UniProt searches. Only modify the lines that change the data package number and the name of the final .xlsx file that will be saved, unless you know what you are doing. ## Uncomment to install missing packages # install.packages(&quot;devtools&quot;) # library(devtools) # install_github(&quot;PNNL-Comp-Mass-Spec/MSnID@pnnl-master&quot;) # install_github(&quot;PNNL-Comp-Mass-Spec/PlexedPiper&quot;) # install_github(&quot;PNNL-Comp-Mass-Spec/PNNL.DMS.utils&quot;) # if (!requireNamespace(&quot;BiocManager&quot;, quietly = TRUE)) # install.packages(&quot;BiocManager&quot;) # BiocManager::install(&quot;MSnbase&quot;) # install.packages(&quot;writexl&quot;) # install.packages(&quot;dplyr&quot;) # install.packages(&quot;tibble&quot;) library(MSnID) library(PlexedPiper) library(PNNL.DMS.utils) library(MSnbase) library(writexl) library(dplyr) library(tibble) # Data package number data_package_num &lt;- 3987 # Name of the final file to save file_name &lt;- &quot;data/3987_spectral_counts.xlsx&quot; Do not modify anything below unless you know what you are doing. # Read MS-GF+ results from the DMS m &lt;- read_msgf_data_from_DMS(data_package_num = data_package_num) # Filter to 1% FDR at the peptide level m &lt;- filter_msgf_data(m, level = &quot;peptide&quot;, fdr.max = 0.01) # UniProt to gene symbol conversion table conv_tab &lt;- fetch_conversion_table(organism_name = &quot;Homo sapiens&quot;, from = &quot;UNIPROT&quot;, to = &quot;SYMBOL&quot;) When running fetch_conversion_table, if a prompt appears that requires an answer, type yes and press enter. # Modify accessions column of psms to use gene symbols m &lt;- remap_accessions(m, conv_tab, &quot;\\\\|([^|-]+)(-\\\\d+)?\\\\|&quot;) # Do the same remapping to the FASTA file fst_path &lt;- path_to_FASTA_used_by_DMS(data_package_num = data_package_num) fst_path_2 &lt;- remap_fasta_entry_names( path_to_FASTA = fst_path, conversion_table = conv_tab, extraction_pttrn = &quot;\\\\|([^|-]+)(-\\\\d+)?\\\\|&quot; ) # Compute the number of amino acids per 1000 and use that to filter # to 1% FDR at the protein level m &lt;- compute_num_peptides_per_1000aa(m, fst_path_2) m &lt;- filter_msgf_data(m, &quot;accession&quot;, fdr.max = 0.01) # Parsimonious protein inference m &lt;- infer_parsimonious_accessions(m) show(m) # Assessment of filtering quality ## MSnID object ## Working directory: &quot;.&quot; ## #Spectrum Files: 8 ## #PSMs: 114125 at 0.012 % FDR ## #peptides: 23209 at 0.043 % FDR ## #accessions: 2362 at 0.38 % FDR The results look reasonable, so we will continue on to spectral counting. # Remove decoys m &lt;- apply_filter(m, &quot;!isDecoy&quot;) # Convert m to an MSnSet msnset &lt;- as(m, &quot;MSnSet&quot;) # Spectral counting: # Within each accession group, sum the values within columns. msnset &lt;- combineFeatures(msnset, fData(msnset)$accession, redundancy.handler = &quot;multiple&quot;, method = &quot;sum&quot;, cv = FALSE) # Sort features from most to least abundant tot_count &lt;- rowSums(exprs(msnset)) msnset &lt;- msnset[order(-tot_count), ] # Save exprs as an .xlsx file msnset %&gt;% exprs() %&gt;% as.data.frame() %&gt;% rownames_to_column(&quot;Gene&quot;) %&gt;% write_xlsx(path = file_name) "],["id-conversion.html", "Section 4 Feature ID Conversion", " Section 4 Feature ID Conversion This section shows how to convert from one feature ID (UniProt accessions, gene symbols, etc.) to another using different packages. "],["conversion-with-biomart.html", "4.1 Conversion with biomaRt", " 4.1 Conversion with biomaRt ## Install missing packages if (!require(&quot;BiocManager&quot;, quietly = TRUE)) install.packages(&quot;BiocManager&quot;) bio_pkgs &lt;- c(&quot;biomaRt&quot;, &quot;Biostrings&quot;) for (pkg_i in bio_pkgs) { if (!require(pkg_i, quietly = T, character.only = T)) BiocManager::install(pkg_i) } if (!require(&quot;remotes&quot;, quietly = T)) install.packages(&quot;remotes&quot;) if (!require(&quot;MSnID&quot;, quietly = T, character.only = T)) remotes::install_github(&quot;PNNL-Comp-Mass-Spec/MSnID@pnnl-master&quot;) ## ------------------------ library(biomaRt) # ID conversion library(Biostrings) # read FASTA files library(MSnID) # parse_FASTA_names The first steps are to determine which mart and dataset to use. listMarts will show the available marts. The first 6 rows of the available datasets (provided by listDatasets(mart)) are also shown. (Use View, rather than head, to search for the desired database.) # Create mart listMarts() # determine biomart for useMart ## biomart version ## 1 ENSEMBL_MART_ENSEMBL Ensembl Genes 106 ## 2 ENSEMBL_MART_MOUSE Mouse strains 106 ## 3 ENSEMBL_MART_SNP Ensembl Variation 106 ## 4 ENSEMBL_MART_FUNCGEN Ensembl Regulation 106 mart &lt;- useMart(biomart = &quot;ENSEMBL_MART_ENSEMBL&quot;) head(listDatasets(mart)) # determine dataset for useMart ## dataset description ## 1 abrachyrhynchus_gene_ensembl Pink-footed goose genes (ASM259213v1) ## 2 acalliptera_gene_ensembl Eastern happy genes (fAstCal1.2) ## 3 acarolinensis_gene_ensembl Green anole genes (AnoCar2.0v2) ## 4 acchrysaetos_gene_ensembl Golden eagle genes (bAquChr1.2) ## 5 acitrinellus_gene_ensembl Midas cichlid genes (Midas_v5) ## 6 amelanoleuca_gene_ensembl Giant panda genes (ASM200744v2) ## version ## 1 ASM259213v1 ## 2 fAstCal1.2 ## 3 AnoCar2.0v2 ## 4 bAquChr1.2 ## 5 Midas_v5 ## 6 ASM200744v2 mart &lt;- useMart(biomart = &quot;ENSEMBL_MART_ENSEMBL&quot;, dataset = &quot;rnorvegicus_gene_ensembl&quot;) Next, we determine which attributes to select for the conversion table with listAttributes(mart). From that table, we select “refseq_peptide” and “external_gene_name”. # Create conversion table head(listAttributes(mart)) # determine attributes for getBM ## name description page ## 1 ensembl_gene_id Gene stable ID feature_page ## 2 ensembl_gene_id_version Gene stable ID version feature_page ## 3 ensembl_transcript_id Transcript stable ID feature_page ## 4 ensembl_transcript_id_version Transcript stable ID version feature_page ## 5 ensembl_peptide_id Protein stable ID feature_page ## 6 ensembl_peptide_id_version Protein stable ID version feature_page conv_tbl1 &lt;- getBM(attributes = c(&quot;refseq_peptide&quot;, &quot;external_gene_name&quot;), mart = mart) head(conv_tbl1, 10) ## refseq_peptide external_gene_name ## 1 ## 2 AC118165.1 ## 3 NP_001000130 Olr56 ## 4 NP_001000302 Olr473 ## 5 AC099294.1 ## 6 AABR07054368.1 ## 7 Olr760 ## 8 NP_001014048 Clrn3 ## 9 AABR07000137.1 ## 10 NP_001011937 Doc2g This table has a lot of blank entries that need to be removed. "],["conversion-with-annotationhub.html", "4.2 Conversion with AnnotationHub", " 4.2 Conversion with AnnotationHub ## Install missing packages if (!require(&quot;remotes&quot;, quietly = T)) install.packages(&quot;remotes&quot;) if (!require(&quot;MSnID&quot;, quietly = T)) remotes::install_github(&quot;PNNL-Comp-Mass-Spec/MSnID@pnnl-master&quot;) MSnID has a function called fetch_conversion_table that leverages AnnotationHub to create a conversion table. # Create conversion table with MSnID::fetch_conversion_table conv_tbl2 &lt;- fetch_conversion_table( organism_name = &quot;Rattus norvegicus&quot;, from = &quot;REFSEQ&quot;, to = &quot;SYMBOL&quot; ) head(conv_tbl2, 10) ## REFSEQ SYMBOL ## 1 NP_443211 Asip ## 2 NP_036620 A2m ## 3 XP_038962922 A2m ## 4 XP_038962923 A2m ## 5 NP_001382591 Acaa1a ## 6 NP_036621 Acaa1a ## 7 XP_038936714 Acaa1a ## 8 XP_038936715 Acaa1a ## 9 NP_058682 Acadm ## 10 NP_001104565 Acly "],["conversion-using-fasta-headers.html", "4.3 Conversion Using FASTA Headers", " 4.3 Conversion Using FASTA Headers If specifically converting to gene symbols, it is recommended to use the information in the headers of the FASTA file that was used for the database search. The gene symbol is always given by GN=..., so we can use a regular expression to extract it. For UniProt FASTA files, there is a function in MSnID called parse_FASTA_names that will extract the components of the FASTA headers and create a data.frame. ## Read FASTA file fst_path &lt;- system.file(&quot;extdata/uniprot_rat_small.fasta.gz&quot;, package = &quot;MSnID&quot;) conv_tbl3 &lt;- parse_FASTA_names(path_to_FASTA = fst_path) head(conv_tbl3) ## feature database uniprot_acc isoform entry_name ## 1 sp|P63088|PP1G_RAT sp P63088 NA PP1G_RAT ## 2 sp|Q4FZV7|TMUB2_RAT sp Q4FZV7 NA TMUB2_RAT ## 3 sp|O55159|EPCAM_RAT sp O55159 NA EPCAM_RAT ## 4 sp|Q80VJ4|GPCP1_RAT sp Q80VJ4 NA GPCP1_RAT ## 5 sp|Q66MI6|T10IP_RAT sp Q66MI6 NA T10IP_RAT ## 6 sp|O70453|HMOX3_RAT sp O70453 NA HMOX3_RAT ## description ## 1 Serine/threonine-protein phosphatase PP1-gamma catalytic subunit ## 2 Transmembrane and ubiquitin-like domain-containing protein 2 ## 3 Epithelial cell adhesion molecule ## 4 Glycerophosphocholine phosphodiesterase GPCPD1 ## 5 Testis-specific protein 10-interacting protein ## 6 Putative heme oxygenase 3 ## organism organism_id gene protein_existence sequence_version ## 1 Rattus norvegicus 10116 Ppp1cc 1 1 ## 2 Rattus norvegicus 10116 Tmub2 2 1 ## 3 Rattus norvegicus 10116 Epcam 1 1 ## 4 Rattus norvegicus 10116 Gpcpd1 1 1 ## 5 Rattus norvegicus 10116 Tsga10ip 2 2 ## 6 Rattus norvegicus 10116 Hmox3 5 1 "],["exploratory-data-analysis.html", "Section 5 Exploratory Data Analysis", " Section 5 Exploratory Data Analysis Exploratory Data Analysis (EDA) is an important step before any sort of statistical analyses. The goal of EDA is to get a big picture view of the data and identify potential outlier samples and batch effects that need to be corrected. For this section, we need the MSnSet.utils package, which contains the cptac_oca data that we will use to illustrate these EDA approaches, as well as the plot_pca function for creating PCA plots of samples. ## Install missing packages if (!require(&quot;remotes&quot;, quietly = T)) install.packages(&quot;remotes&quot;) if (!require(&quot;MSnSet.utils&quot;, quietly = T)) remotes::install_github(&quot;PNNL-Comp-Mass-Spec/MSnSet.utils&quot;) ## ------------------------ library(MSnSet.utils) # Load the example MSnSet data(cptac_oca) "],["count-features-in-samples.html", "5.1 Count Features in Samples", " 5.1 Count Features in Samples To count the number of features identified in each sample, we use colSums to tally the number of entries that are not NA in each column of exprs(oca.set). # Calculate the number of proteins identified (not NA) in each sample oca.set$num_proteins &lt;- colSums(!is.na(exprs(oca.set))) Now that we have a vector of the number of proteins detected in each sample stored in pData(oca.set), there are a few ways to present it. The first is a simple summary, which is accomplished with the summary function. This outputs the average value, as well as a 5-number summary that includes the minimum, the 1st quartile, the median (2nd quartile), the 3rd quartile, and the maximum value. summary(oca.set$num_proteins) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 6594 6957 7286 7225 7463 7798 The 5-number summary can also be presented as a boxplot, which is typically more useful at a glance. Below is an example of how to create a horizontal boxplot. # Horizontal boxplot boxplot(oca.set$num_proteins, horizontal = TRUE, xlab = &quot;Number of Proteins Detected&quot;) Boxplots are useful, but a lot of the finer details about the distribution are lost when summarizing. To remedy this, we could instead show a scatterplot of the individual values with the base plot function. We will change the point type with pch to plot solid circles and change the axis titles with xlab and ylab. plot(oca.set$num_proteins, pch = 19, xlab = &quot;Sample Index&quot;, ylab = &quot;Number of Proteins Detected&quot;) While harder to interpret at a glance than a boxplot, scatterplots are useful for identifying potential outliers and possible trends in the data. In the plot above, it doesn’t appear than there are any samples with significantly fewer identifications. The other plot type we could use balances the summary of the boxplot with the finer detail of the scatterplot: kernel density plots. We can use a combination of stats::density and base::plot to quickly create a density plot. # Kernel density plot plot(density(oca.set$num_proteins, na.rm = TRUE), xlim = range(oca.set$num_proteins, na.rm = TRUE), main = &quot;Density Plot&quot;, xlab = &quot;Number of Proteins Detected&quot;) It looks like there are peaks around 6900-7000 and 7300-7500 proteins. "],["sample-boxplots.html", "5.2 Sample Boxplots", " 5.2 Sample Boxplots boxplot(exprs(oca.set)) "],["estimate-blood-contamination.html", "5.3 Estimate Blood Contamination", " 5.3 Estimate Blood Contamination Strong contamination of samples with blood may lead to the inability to identify low-abundant proteins, so it is important to estimate the level of blood contamination. We can search for major blood proteins with the grepl function and summarize their abundances within each sample to obtain reasonable estimates. We will need to search for the blood protein identifiers that match the protein identifiers in the MSnSet. Since we are using the cptac_oca data for these examples, we will need to know the NCBI RefSeq protein IDs for the following blood proteins: hemoglobin, fibrinogen, albumin, and spectrin. Unfortunately, this means manually searching for these identifiers, which are provided in the list below. hemoglobin subunit alpha 1: NP_000549.1 subunit alpha 2: NP_000508.1 subunit beta: NP_000509.1 subunit gamma-1: NP_000550.2 subunit gamma-2: NP_000175.1 albumin: NP_000468.1 fibrinogen alpha chain isoform alpha precursor: NP_068657.1 alpha chain isoform alpha-E preprotein: NP_000499.1 spectrin alpha chain, erythrocytic 1: NP_003117.2 beta chain, erythrocytic 1: NP_001342365.1 We need to create a vector of these blood protein IDs. We will use this to check if each feature is a blood protein. Doing so will create a logical vector that we can use to subset the data to the abundance values of those matches. With the subset data, we can then calculate the column (sample) averages with colMeans to get a single vector that estimates the average blood contamination of each sample. # Blood protein IDs blood_prot &lt;- c(&quot;NP_000549.1&quot;, &quot;NP_000508.1&quot;, &quot;NP_000509.1&quot;, &quot;NP_000550.2&quot;, &quot;NP_000175.1&quot;, &quot;NP_000468.1&quot;, &quot;NP_068657.1&quot;, &quot;NP_000499.1&quot;, &quot;NP_003117.2&quot;, &quot;NP_001342365.1&quot;) # Select entries that match one of the blood proteins idx &lt;- featureNames(oca.set) %in% blood_prot # indexing matches blood_contam &lt;- colMeans(exprs(oca.set)[idx, ], na.rm = TRUE) # sample means We can visualize the blood contamination with any of the previously shown methods for visualizing the number of protein identifications. We will use a density plot. # Kernel density plot plot(density(blood_contam, na.rm = TRUE), xlim = range(blood_contam, na.rm = TRUE), main = &quot;Blood Contamination&quot;, xlab = &quot;Average Protein Abundance&quot;) "],["pca.html", "5.4 PCA", " 5.4 PCA Principal Component Analysis (PCA) is an unsupervised dimensionality reduction technique. It is useful for visualizing high-dimensional data in a lower-dimensional (usually 2D) space while retaining as much information from the original data as possible. It does this by creating linear combinations of features called principal components in such a way that that the first principal component (PC1) explains the most variation in the original data, PC2 explains the second most, and so on. Typically, we create scatterplots of PC1 vs PC2 to visualize relationships between samples with the plot_pca function from the MSnSet.utils package. PCA plots are used to check for batch effects and sample differences due to variables of interest. If samples appear to separate by group or according to a continuous variable and the first two principal components explain a decent percentage of the variance in the original data, then we are fairly confident that the predictor affected the data in some way or is at least correlated to something that did. Note that while there are PCA methods that allow some degree of missing data (see pcaMethods::pca for details), plot_pca makes use of the prcomp function, which does not. We do not need to filter data prior to running plot_pca, as it handles that and prints a message to tell us how many complete rows remained. If there are very few complete features, PCA will still work, but the results may not be very meaningful. In this case, it may be a good idea to impute missing values. We will begin with the base plot. The axis titles show how much variance in the original data is explained by each component. This is built with the ggplot2 package, so it can be customized with other functions in the package. # Default plot plot_pca(oca.set) Of the total 8103 features, 4738 were present in all 73 samples and used for PCA. Also notice that PC1 and PC2 explain less than 1/5 of the variance in the original data. Now, we will color points according to their “SUBTYPE” group label and add a 50% Normal confidence ellipse for each group. We could remove the ellipse by setting show_ellipse to FALSE. We will also change the legend title to “Subtype”. # Points colored by SUBTYPE plot_pca(oca.set, phenotype = &quot;SUBTYPE&quot;, legend_title = &quot;Subtype&quot;) It looks like samples slightly separate by SUBTYPE, and there may be features that are statistically different between the Proliferative and Mesenchymal groups. Something to keep in mind when performing differential analysis. Now, we will check for potential batch effects by coloring points by their “Batch” group. # Points colored by Batch plot_pca(oca.set, phenotype = &quot;Batch&quot;) For the most part, it seems like all of the batches overlap and are somewhat centered on the origin (aside from batch X17). It is difficult to determine if there is a batch effect, so it may be a good idea to correct for it anyway. This is covered in a different section. We can also use this function to identify the most influential features in PCA space with the biplot argument. plot_pca(oca.set, phenotype = &quot;SUBTYPE&quot;, biplot = TRUE, label_args = list(color = &quot;black&quot;)) From the biplot, we can see that proteins that begin with “NP_9976” are major drivers in the separation of the Mesenchymal and Proliferative samples. Similarly, we can see that there are a few blood proteins (hemoglobin subunits: NP000549.1 and NP_000550.2) that are major drivers of separation along PC2, though PC2 only explains about 6% of the variance in the original data. See ?plot_pca for more customization options. "],["heatmaps.html", "Section 6 Heatmaps", " Section 6 Heatmaps Heatmaps are graphical representations of matrices that use color to show differences in values. They are useful for detecting overall patterns in data, as they can show how features and samples relate to each other or how features change according to some phenotype of interest. In this section, we will explore how to create expression and correlation heatmaps from MSnSet objects, as well as how to improve the appearance of these heatmaps. We will need the following packages and MSnSet. library(MSnSet.utils) # complex_heatmap library(circlize) # colorRamp2 library(ComplexHeatmap) # additional modifications library(dplyr) # %&gt;% # Data data(&quot;longitudinal_biomarker_study&quot;) # Shorten name m &lt;- longitudinal_biomarker_study "],["expression-heatmaps.html", "6.1 Expression Heatmaps", " 6.1 Expression Heatmaps A heatmap of the expression matrix of an MSnSet with features as rows and samples as columns. The data is assumed to be zero-centered. By default, row and column names are not shown. See ?complex_heatmap for how to change this. # Base expression heatmap complex_heatmap(m) # Change color range to better detect patterns complex_heatmap(m, color_range = c(-1.5, 1.5)) # Change heatmap title and legend title complex_heatmap(m, heatmap_title = &quot;This is the heatmap title&quot;, heatmap_legend_title = &quot;Legend\\nTitle&quot;) "],["correlation-heatmaps.html", "6.2 Correlation Heatmaps", " 6.2 Correlation Heatmaps When the heatmap_type argument is (an abbreviation of) \"sample_correlation\" or \"feature_correlation\", complex_heatmap constructs the matrix of correlations (default cor_method = \"pearson\") between samples or features and generates a heatmap. Correlation heatmaps become even more useful when annotated (Section 6.3). 6.2.1 Sample Correlation # Sample correlation heatmap complex_heatmap(m, heatmap_type = &quot;sample&quot;) 6.2.2 Feature Correlation # Feature correlation heatmap complex_heatmap(m, heatmap_type = &quot;feature&quot;) "],["heatmap-annotation.html", "6.3 Heatmap Annotation", " 6.3 Heatmap Annotation To annotate columns and rows of the heatmap, we use the anno_column and anno_row arguments, respectively. anno_column takes a vector of one or more strings that correspond to the names of columns in pData, and anno_row takes a vector of one or more strings that correspond to the names of column in fData. By default, MSnSet.utils::jet2.colors is used for character, factor, and logical values, and circlize::colorRamp2 with a viridis color palette is used for numeric values. When annotating sample correlation heatmaps, only anno_column may be specified. Similarly, when annotating feature correlation heatmaps, only anno_row may be specified. Row or column annotations will be included along the other axis. We will annotate the rows using values in the \"isSpike\" (logical) column of fData(m) and annotate rows using the values in the \"Type\" (factor) and \"Age\" (numeric) columns of pData(m). # Expression heatmap with row and column annotation complex_heatmap(m, anno_row = &quot;isSpike&quot;, anno_column = c(&quot;Type&quot;, &quot;Age&quot;)) 6.3.1 Modifying Default Colors We can change the colors of row and column annotations by passing lists to anno_row_colors and anno_column_colors, respectively. For example, we will change the colors of \"Type\" so that “Control” is a different shade of blue (“#414DBE”) and “Case” is a dark yellow (#BEB241). We will also change the colors of \"Age\" so that the minimum value is white and the maximum value is dark red. Since age is a numeric column, we must use circlize:colorRamp2. Tip: Use palettes from the RColorBrewer package, an interactive color wheel (like this one from canva), or a color palette generator (like this one also from canva) to find colors. # Modify colors for Type and Age complex_heatmap(m, anno_column = c(&quot;Type&quot;, &quot;Age&quot;), anno_column_colors = list( Type = c(&quot;#414DBE&quot;, &quot;#BEB241&quot;), Age = circlize::colorRamp2( breaks = range(m$Age, na.rm = TRUE), colors = c(&quot;white&quot;, &quot;darkred&quot;)) )) "],["modifications.html", "6.4 Modifications", " 6.4 Modifications heatmap_args and anno_args are used to modify the heatmaps: changing the row and column labels, labeling specific features, changing the colors of labels, changing font size, adding different types of annotations, splitting rows or columns into groups, etc. The ComplexHeatmap Complete Reference goes more into detail about each of these modifications, but we will cover a few of them in this section. We will use a random subset of the MSnSet to explore some of these modifications. This is just so we can see the row and column names more easily. set.seed(99) # subset to 25 features and 40 samples m_sub &lt;- m[sample(1:nrow(m), size = 25), sample(1:ncol(m), size = 40)] 6.4.1 Row and column labels By default, the row and column labels are the row and column names of the matrix passed to Heatmap. In the case of the default expression heatmap, the row names are the featureNames of the MSnSet and the column names are the sampleNames. We can instead use any column in fData and any column in pData to label the rows and columns, respectively. Duplicate labels are also allowed, which is especially useful if there are multiple peptides that map to the same protein, multiple proteins that map to the same gene, etc. # Default row labels - peptides complex_heatmap(m_sub, show_row_names = TRUE, heatmap_title = &quot;Default Row Labels&quot;) Suppose, for example, we want to label the rows by the Protein column of fData(m_sub). We can do this by modifying the row_labels argument of ComplexHeatmap::Heatmap with the heatmap_args list. We will also reduce the font size of the labels so that they do not overlap. # Label rows with proteins and change font size complex_heatmap(m_sub, show_row_names = TRUE, heatmap_title = &quot;New Row Labels&quot;, heatmap_args = list(row_labels = fData(m_sub)[[&quot;Protein&quot;]], # Change font size of row labels row_names_gp = gpar(fontsize = 10))) 6.4.2 Label colors # One color complex_heatmap(m_sub, show_row_names = TRUE, heatmap_args = list(row_names_gp = gpar(col = &quot;orange&quot;))) # Multiple colors # If peptide begins with &quot;A&quot;, color it red # If peptide begins with &quot;G&quot;, color it blue # Otherwise, color it black row_colors &lt;- featureNames(m_sub) %&gt;% {case_when(grepl(&quot;^A&quot;, .) ~ &quot;red&quot;, grepl(&quot;^G&quot;, .) ~ &quot;blue&quot;, TRUE ~ &quot;black&quot;)} complex_heatmap(m_sub, show_row_names = TRUE, heatmap_args = list( row_names_gp = gpar(col = row_colors))) 6.4.3 Label specific features We can use mark annotation to label specific features or samples. For this example, we will label all non-human proteins. We need the indices of the proteins to label and the column in fData used to select these labels. # Indices of non-human proteins idx &lt;- which(!grepl(&quot;HUMAN&quot;, fData(m)[[&quot;Protein&quot;]])) # Row annotation object. The name can be anything, so we just use anno ra &lt;- rowAnnotation(anno = anno_mark(at = idx, labels = fData(m)[[&quot;Protein&quot;]][idx])) # Heatmap with labels for select features complex_heatmap(m, heatmap_args = list(row_labels = fData(m)[[&quot;Protein&quot;]], right_annotation = ra)) 6.4.4 Heatmap body color complex_heatmap(m, heatmap_args = list(col = circlize::colorRamp2( breaks = c(min(exprs(m), na.rm = TRUE), 0, max(exprs(m), na.rm = TRUE)), colors = c(&quot;purple&quot;, &quot;white&quot;, &quot;orange&quot;) )) ) If changing the colors of the heatmap body, color_range will not work. Instead, the breaks and colors need to be modified so that the minimum value and the lower limit are the same color and the maximum value and the upper limit are the same color. complex_heatmap(m, heatmap_args = list(col = circlize::colorRamp2( breaks = c(min(exprs(m), na.rm = TRUE), -1.5, 0, 1.5, # add color limits max(exprs(m), na.rm = TRUE)), colors = c(&quot;purple&quot;, &quot;purple&quot;, &quot;white&quot;, &quot;orange&quot;, &quot;orange&quot;) )) ) 6.4.5 Horizontal heatmaps To create a horizontal heatmap, we need to take the transpose of the MSnSet. This will switch the phenoData and featureData. We will also reverse the order of the rows prior to the transpose so that the heatmap would appear to be rotated 90 degrees if samples were not clustered. # Rotate MSnSet m_rot &lt;- t(m[, ncol(m):1]) m_rot ## MSnSet (storageMode: lockedEnvironment) ## assayData: 236 features, 300 samples ## element names: exprs ## protocolData: none ## phenoData ## sampleNames: NTVISVFGASGDLAK TFPALFGLFR ... LLAEPVPGIK (300 total) ## varLabels: Organism Protein Peptide isSpike ## varMetadata: labelDescription ## featureData ## featureNames: QC.24 QC.23 ... X03_C_B (236 total) ## fvarLabels: Sample isQC ... Age (12 total) ## fvarMetadata: labelDescription ## experimentData: use &#39;experimentData(object)&#39; ## Annotation: ## - - - Processing information - - - ## Subset [308,236][300,236] Fri Nov 9 15:22:49 2018 ## Subset [300,236][300,236] Fri May 27 21:19:56 2022 ## MSnSet transposed [Fri May 27 21:19:56 2022] ## MSnbase version: 2.7.11 We will annotate rows to show that it worked. # Horizontal heatmap with row annotations complex_heatmap(m_rot, anno_row = &quot;Age&quot;) 6.4.6 Legends Modifying legends with draw_args, heatmap_args, and anno_args. Below, we change the direction of the heatmap legend and continuous annotation legends to horizontal, change position of annotation titles to top left, and set the number of rows for discrete annotation legends to 1. We also change the width of the “Age” legend to 28 mm, move the legends to the bottom of the heatmap, and set the space between the legends to 10 mm. # Horizontal legends at the bottom complex_heatmap(m, anno_column = c(&quot;Type&quot;, &quot;Age&quot;), # horizontal heatmap legend heatmap_args = list( heatmap_legend_param = list(direction = &quot;horizontal&quot;) ), # horizontal annotation legend anno_args = list( annotation_legend_param = list( title_position = &quot;lefttop&quot;, legend_width = unit(28, &quot;mm&quot;), direction = &quot;horizontal&quot;, # for continuous legends nrow = 1 # for discrete legends ) ), # Place legends at bottom of heatmap draw_args = list(heatmap_legend_side = &quot;bottom&quot;, legend_gap = unit(10, &quot;mm&quot;)) ) "],["DEA.html", "Section 7 Differential Analysis", " Section 7 Differential Analysis In this section, we will use wrappers around functions from the limma package to fit linear models (linear regression, t-test, and ANOVA) to proteomics data. While LIMMA was originally intended for use with microarray data, it is useful for other data types. When working with LIMMA, the LIMMA User’s Guide is an invaluable resource. LIMMA makes use of empirical Bayes techniques to borrow information across all features being tested to increase the degrees of freedom available for the test statistics. This results in so-called moderated test statistics and improved power to detect differential expression (Gordon K. Smyth, 2004). We will use the CPTAC ovarian cancer proteomics dataset for this section. The required packages are MSnSet.utils for the LIMMA wrappers and volcano plots, dplyr for data frame manipulation, and ggplot2 for p-value histograms and to further customize the volcano plots. We load the cptac_oca data and assign oca.set to m, which will be used in the examples. ## Install missing packages cran_packages &lt;- c(&quot;remotes&quot;, &quot;dplyr&quot;, &quot;ggplot2&quot;) for (pkg_i in cran_packages) { if (!require(pkg_i, quietly = T, character.only = T)) install.packages(pkg_i) } if (!require(&quot;MSnSet.utils&quot;, quietly = T)) remotes::install_github(&quot;PNNL-Comp-Mass-Spec/MSnSet.utils&quot;) ## ------------------------ library(MSnSet.utils) library(dplyr) library(ggplot2) # MSnSet for testing data(&quot;cptac_oca&quot;) m &lt;- oca.set References "],["linear-reg.html", "7.1 Linear Regression", " 7.1 Linear Regression limma_a_b or limma_gen are used to perform linear regression, which models the linear relationship between a numeric predictor and the feature-wise values in the exprs slot of an MSnSet. For this example, we will test the AGE column of pData(m). The model.str is the full model that includes the variable of interest and any covariates. The coef.str argument is the variable of interest. lm_res &lt;- limma_gen(m, model.str = &quot;~ AGE&quot;, coef.str = &quot;AGE&quot;) head(arrange(lm_res, adj.P.Val)) # top 6 rows sorted by adjusted p-value ## logFC AveExpr t P.Value adj.P.Val ## NP_001077077.1 -0.10468905 -4.163336e-17 -4.186740 0.0001865011 0.5982300 ## NP_001138679.1 0.01185948 7.806256e-18 3.821284 0.0002953129 0.5982300 ## NP_003286.1 0.01335415 -6.938894e-18 3.870673 0.0002292102 0.5982300 ## NP_055336.1 -0.01819954 1.233581e-18 -3.986807 0.0002306581 0.5982300 ## NP_000026.2 -0.01689006 -5.703200e-18 -2.847600 0.0056747708 0.8201268 ## NP_000176.2 -0.02059760 -3.802134e-18 -3.055901 0.0031033317 0.8201268 ## B ## NP_001077077.1 0.001863506 ## NP_001138679.1 -1.049384099 ## NP_003286.1 -0.880645496 ## NP_055336.1 -0.598496581 ## NP_000026.2 -3.895795433 ## NP_000176.2 -3.338485703 The logFC column is the slope of the regression line, and the AveExpr column is the average of the values for that feature (same as rowMeans(exprs(m), na.rm = TRUE)). AveExpr can also be thought of as the y-intercept of the regression line when the predictor is mean-centered. The actual y-intercept is \\(\\text{AveExpr} - avg(\\text{AGE})\\cdot\\text{logFC}\\). The other columns are t moderated t-statistic P.Value p-value adj.P.Val p-values adjusted with the Benjamini-Hocheberg procedure B log-odds of differential expression Since the table was sorted by adjusted p-value, and the lowest adjusted p-value is ~0.6, none of the features have a significant linear relationship with AGE (after adjustment for multiple comparisons). Below is a graphical representation of the results for a specific feature. This is not a required plot; it is just to visually explain the results. To adjust for the presence of one or more covariates, such as accounting for batch differences, we modify the model.str argument. For this example, we will include Batch as a covariate. We add it after the variable being tested. # Include SUBTYPE as a covariate lm_res_cov &lt;- limma_gen(m, model.str = &quot;~ AGE + Batch&quot;, coef.str = &quot;AGE&quot;) head(arrange(lm_res_cov, adj.P.Val)) ## logFC AveExpr t P.Value adj.P.Val ## NP_002104.2 -0.02214664 -9.315227e-18 -3.711539 4.238866e-04 0.5057768 ## NP_002635.2 -0.05455354 -3.128810e-17 -4.266737 9.198715e-05 0.5057768 ## NP_003286.1 0.01432046 -6.938894e-18 3.801188 3.156548e-04 0.5057768 ## NP_005657.1 -0.02421416 8.935014e-18 -3.721088 4.108575e-04 0.5057768 ## NP_006387.1 0.01887213 -1.368768e-17 3.637909 5.384586e-04 0.5057768 ## NP_006535.1 -0.01271186 -3.041707e-18 -3.698719 4.420011e-04 0.5057768 ## B ## NP_002104.2 -1.3815025 ## NP_002635.2 0.3619802 ## NP_003286.1 -1.1003103 ## NP_005657.1 -1.3517595 ## NP_006387.1 -1.6091557 ## NP_006535.1 -1.4213571 When accounting for differences due to Batch, no features have a significant linear relationship with AGE. Again, we will show a graphical representation of the top feature. "],["t-tests.html", "7.2 Two-Sample t-tests", " 7.2 Two-Sample t-tests Two-sample t-tests are used to determine whether there is a significant difference between the means of two groups. The null hypothesis is that the group means are equal, and the alternative is that they are not equal. Written another way, the null hypothesis is that the difference in means is zero, and the alternative is that the difference is not zero. limma_a_b and limma_contrasts can perform moderated two-sample t-tests. 7.2.1 One comparison If a factor only has two groups, we can use limma_a_b. We will test for differences between the “RESISTANT” and “TREATMENT” groups without accounting for any covariates. # Test RESISTANT - SENSITIVE = 0 t_res1 &lt;- limma_a_b(eset = m, model.str = &quot;~ PLATINUM.STATUS&quot;, coef.str = &quot;PLATINUM.STATUS&quot;) head(arrange(t_res1, adj.P.Val)) # top 6 rows sorted by adjusted p-value ## logFC AveExpr t P.Value adj.P.Val B ## NP_000007.1 0.4924636 0.050292811 2.746579 0.008196829 0.9569777 -3.618784 ## NP_000013.2 -0.2221522 0.062925069 -1.373152 0.175457942 0.9569777 -4.484676 ## NP_000030.1 -0.3525116 -0.051132133 -1.251127 0.216355370 0.9569777 -4.538114 ## NP_000031.1 -0.3487920 0.046000375 -1.248196 0.217418216 0.9569777 -4.539343 ## NP_000032.1 -0.3564539 0.003432085 -1.445320 0.154225965 0.9569777 -4.451000 ## NP_000037.2 -0.2507794 0.041070595 -1.770298 0.087859482 0.9569777 -4.386374 The logFC column is the difference in means between the “RESISTANT” and “SENSITIVE” groups (the first level is always the reference; use levels(m$PLATINUM.STATUS) to check). The other columns are AveExpr overall mean (same as rowMeans(exprs(m), na.rm = TRUE)) t moderated t-statistic P.Value p-values adj.P.Val BH-adjusted p-values B log-odds of differential expression/abundance Below is a graphical representation of the results for a specific feature. This is not a required step. It is just to visually explain the results. The next step would be to check the p-value histograms. If those look fine, we can tally the number of significant features. # TRUE - significant, FALSE - not significant table(t_res1$adj.P.Val &lt; 0.05) ## ## FALSE ## 8101 None of the features are significantly different between the two PLATINUM.STATUS groups at the 0.05 FDR level. 7.2.2 Multiple comparisons Now, we will move on to an example of how to use limma_contrasts, which is suited for comparing groups against a reference. We will treat “Immunoreactive” as the reference group for this example, though this does not really make sense in the context of this data. It would make more sense to do a one-way ANOVA with limma_gen (Section 7.3). This is just for example purposes. We will test the following contrasts. Each level must begin with the variable name, or limma_contrasts will not work. # Contrasts to test contrasts &lt;- paircomp(x = m$SUBTYPE, name = &quot;SUBTYPE&quot;, ref = &quot;Immunoreactive&quot;) contrasts ## [1] &quot;SUBTYPEProliferative-SUBTYPEImmunoreactive&quot; ## [2] &quot;SUBTYPEMesenchymal-SUBTYPEImmunoreactive&quot; ## [3] &quot;SUBTYPEDifferentiated-SUBTYPEImmunoreactive&quot; By default, limma_contrasts generates diagnostic plots. For now, we will not make these plots. We also need to specify a no-intercept model by including 0 in model.str. # Test contrasts t_res2 &lt;- limma_contrasts(eset = m, model.str = &quot;~ 0 + SUBTYPE&quot;, coef.str = &quot;SUBTYPE&quot;, contrasts = contrasts, trend = TRUE, robust = TRUE, # passed to eBayes plot = FALSE) head(arrange(t_res2, adj.P.Val)) # top 6 rows sorted by adjusted p-value ## RefSeq logFC AveExpr t P.Value adj.P.Val ## 1: NP_000388.2 -1.2232098 -3.421920e-18 -7.703025 4.549213e-11 1.105868e-06 ## 2: NP_001944.1 -1.3465807 -5.322987e-18 -6.637345 4.520647e-09 3.191542e-05 ## 3: NP_112092.1 -1.0268282 -9.315227e-18 -6.602133 5.251623e-09 3.191542e-05 ## 4: NP_002323.2 0.6707465 3.564500e-18 6.698537 3.482606e-09 3.191542e-05 ## 5: NP_001120963.1 -0.9267318 -2.281280e-18 -6.358267 1.475334e-08 7.172780e-05 ## 6: NP_009005.1 -1.0097220 -1.273715e-17 -6.243353 2.392300e-08 8.017389e-05 ## B feature contrast ## 1: 14.750586 NP_000388.2 Proliferative-Immunoreactive ## 2: 10.463800 NP_001944.1 Proliferative-Immunoreactive ## 3: 10.323954 NP_112092.1 Proliferative-Immunoreactive ## 4: 10.602125 NP_002323.2 Mesenchymal-Immunoreactive ## 5: 9.360149 NP_001120963.1 Proliferative-Immunoreactive ## 6: 8.909146 NP_009005.1 Proliferative-Immunoreactive In addition to the columns from the output of limma_a_b, limma_contrasts creates a column for the contrasts and includes all columns from fData. It is important to note that p-values in the adj.P.Val column have been adjusted across all features and contrasts, so testing more contrasts results in fewer significant features. It is best to test only a small number of related contrasts. Below is a graphical representation of the results for a specific feature. The next step would be to check the p-value histograms. If those look fine, we can tally the number of significant features. # TRUE - significant, FALSE - not significant table(t_res2$contrast, t_res2$adj.P.Val &lt; 0.05) ## ## FALSE TRUE ## Differentiated-Immunoreactive 8052 51 ## Mesenchymal-Immunoreactive 7908 195 ## Proliferative-Immunoreactive 7848 255 If we take the 51, 195, and 255 features with the lowest adjusted p-values from the “Differentiated-Immunoreactive”, “Mesenchymal-Immunoreactive”, and “Proliferative-Immunoreactive” comparisons, respectively, the overall estimated FDR is at most 0.05. That is, we expect ~25 out of those 501 to be false positives. More features are significantly different between the “Proliferative” and “Immunoreactive” groups than in the other comparisons. "],["anova.html", "7.3 One-Way ANOVA", " 7.3 One-Way ANOVA A one-way ANOVA is a generalized version of the two-sample t-test that is used to determine whether there is a significant difference between the means of three or more groups. The null hypothesis is that all group means are equal, and the alternative is that at least one of the means is different from the rest. Written another way, the null hypothesis is that the difference between any two means is zero, and the alternative is that the difference between at least two means is not zero. Note: A one-way ANOVA does not tell us which means are different—only that a difference exists. MSnSet.utils::limma_gen is a wrapper around functions from the limma package that performs one-way ANOVA. We will use it to test if there is a significant difference between any two levels of SUBTYPE: “Immunoreactive”, “Proliferative”, “Mesenchymal”, and “Differentiated”. Since SUBTYPE is a factor, the first level (“Immunoreactive”) will be used as the reference. That is, we will be testing whether the means of the “Proliferative”, “Mesenchymal”, or “Differentiated” groups are different from the mean of the “Immunoreactive” group for each feature in the MSnSet m. anova_res &lt;- limma_gen(eset = m, model.str = &quot;~ SUBTYPE&quot;, coef.str = &quot;SUBTYPE&quot;) head(arrange(anova_res, adj.P.Val)) # top 6 rows arranged by adjusted p-value ## SUBTYPEProliferative SUBTYPEMesenchymal SUBTYPEDifferentiated ## NP_055140.1 -0.4979740 0.24131186 -0.3342889 ## NP_000388.2 -1.2232098 -0.21980158 -0.7849428 ## NP_009005.1 -1.0097220 0.04832193 -0.6224298 ## NP_000878.2 -0.7633419 0.07176514 -0.5563074 ## NP_001944.1 -1.3465807 -0.17808291 -0.9476618 ## NP_115584.1 -0.2718495 0.93758021 0.1842301 ## AveExpr F P.Value adj.P.Val ## NP_055140.1 2.269399e-18 24.74128 3.642291e-11 2.951348e-07 ## NP_000388.2 -3.421920e-18 23.63972 8.266856e-11 3.349317e-07 ## NP_009005.1 -1.273715e-17 19.72001 1.784885e-09 4.820974e-06 ## NP_000878.2 -1.710960e-18 18.89587 3.521123e-09 5.195885e-06 ## NP_001944.1 -5.322987e-18 19.03216 3.144239e-09 5.195885e-06 ## NP_115584.1 1.172771e-18 18.76318 4.488608e-09 5.195885e-06 The row names are the features that were tested, and the first three columns are the average log2 fold-changes for each contrast: “Proliferative - Immunoreactive”, “Mesenchymal - Immunoreactive”, and “Differentiated - Immunoreactive”. That is, a positive value indicates that the mean of the “Immunoreactive” group is lower than the mean of the other group, and a negative value indicates that the mean of the “Immunoreactive” group is higher than the mean of the other group. To find the logFC between the “Proliferative” and “Mesenchymal” groups for protein NP_055140.1, for example, we would take the difference between “SUBTYPEProliferative” and “SUBTYPEMesenchymal”: -0.498 - 0.241 = -0.739. The other columns are AveExpr overall mean (same as rowMeans(exprs(m), na.rm = TRUE)) F moderated F-statistic P.Value p-value adj.P.Val BH-adjusted p-value Below is a graphical representation of the results for a specific feature. This is not a required step; it is just a visual explanation of the results. The next step would be to check the p-value histograms. If those look fine, we can tally the number of significant features. table(anova_res$adj.P.Val &lt; 0.05) ## ## FALSE TRUE ## 7049 1054 1054 features have adjusted p-values less than 0.05. Since the expected FDR is 0.05, we estimate that at most ~53 of these are false positives. "],["p-value-histograms.html", "7.4 p-value Histograms", " 7.4 p-value Histograms A p-value histogram visualizes the distribution of p-values from a collection of hypothesis tests. It is used as a diagnostic tool to check the validity of results prior to multiple testing correction. hist(t_res1$P.Value, breaks = seq(0, 1, 0.05), main = &quot;Histogram of p-values from PLATINUM.STATUS t-test Results&quot;, xlab = &quot;p-value&quot;) The histogram is uniform, which means it is unlikely that any features will be significantly different between any two PLATINUM.STATUS groups after adjustment for multiple comparisons. Indeed, when we check with sum(t_res1$adj.P.Val &lt; 0.05), none of the features pass the significance threshold after BH adjustment. hist(anova_res$P.Value, breaks = seq(0, 1, 0.05), main = &quot;Histogram of p-values from SUBTYPE ANOVA Results&quot;, xlab = &quot;p-value&quot;) There is a peak around 0 that indicates the null hypothesis is false for some of the tests. If plotting results from limma_contrasts, it is better to use the ggplot2 package to create separate histograms for each contrast. # Histogram faceted by contrast ggplot(t_res2) + geom_histogram(aes(x = P.Value), breaks = seq(0, 1, 0.05), color = &quot;black&quot;, fill = &quot;grey&quot;) + # Remove space between x-axis and min(y) scale_y_continuous(expand = expansion(c(0, 0.05))) + facet_wrap(vars(contrast)) + # separate plots theme_bw(base_size = 12) Based on the p-values, it appears that there are more features that are significantly different between the “Proliferative” vs. “Immunoreactive” comparison than the other two comparisons. The counts were shown at the end of Section 7.2.2. "],["volcano-plots.html", "7.5 Volcano Plots", " 7.5 Volcano Plots Volcano plots are used to summarize the results of differential analysis. They are scatter plots that show log\\(_2\\) fold-change vs statistical significance. The plot_volcano function in the MSnSet.utils package is used to create volcano plots. For ANOVA results, volcano plots will not be useful, since the p-values are based on two or more contrasts; the volcano plots would not display the characteristic “V” shape. 7.5.1 Base plot Unless the differential analysis results are from a one-sample t-test with a single comparison, volcano plots need to be made for each contrast, since there are multiple logFC values for each feature. For this example, we will make a volcano plot using the log\\(_2\\) fold-changes from the t_res1 table. We will set sig_threshold to 0.05, which will add a dashed horizontal line indicating the cutoff for statistical significance. Normally, the adjusted p-values would be used, though they are all extremely high in these results, so we will use the unadjusted p-values for the examples. plot_volcano(df = t_res1, logFC = &quot;logFC&quot;, pvals = &quot;P.Value&quot;, sig_threshold = 0.05) 7.5.2 Label top features plot_volcano has an argument called label to label the top most significant features. By default, the top 8 features will be labelled. The column used for labeling must be in the data frame supplied to the df argument. In this case, we will need to create it using the row names. # Create RefSeq column for labeling t_res1$RefSeq &lt;- rownames(t_res1) # Volcano plot with feature labels plot_volcano(df = t_res1, logFC = &quot;logFC&quot;, pvals = &quot;P.Value&quot;, sig_threshold = 0.05, label = &quot;RefSeq&quot;) # label by RefSeq - top 8 7.5.3 Label specific features There may be cases when the features to label are not necessarily the top \\(n\\). To label specific features, we need a column where everything but the labels are NA, and we need to set num_features to the number of rows in the data so that nothing is discarded. For this example, we will select a random group of 5 features to label. # 5 random RefSeqs to label random_features &lt;- sample(t_res1$RefSeq, size = 5) # If RefSeq is not in the random group of 5, set it to NA t_res1 &lt;- mutate(t_res1, custom_labels = ifelse(RefSeq %in% random_features, RefSeq, NA)) # Volcano plot with feature labels plot_volcano(df = t_res1, logFC = &quot;logFC&quot;, pvals = &quot;P.Value&quot;, sig_threshold = 0.05, # Custom labels label = &quot;custom_labels&quot;, num_features = nrow(t_res1)) 7.5.4 Modify point colors We will change the color of points to reflect their significance and the sign of the log\\(_2\\) fold-change. We start by creating a point_color column with three groups: “down”, “up” and “NS” (not-significant). Then, the point_args argument is modified so that the color of points depends on these groups. # Determine point colors based on significance and sign of the logFC # We would normally use adj.P.Value instead of P.Value t_res1 &lt;- t_res1 %&gt;% mutate(point_color = case_when( P.Value &lt; 0.05 &amp; logFC &lt; 0 ~ &quot;down&quot;, # significantly down P.Value &lt; 0.05 &amp; logFC &gt; 0 ~ &quot;up&quot;, # significantly up TRUE ~ &quot;NS&quot;) # not significant ) # Color points v1 &lt;- plot_volcano(df = t_res1, logFC = &quot;logFC&quot;, pvals = &quot;P.Value&quot;, sig_threshold = 0.05, # Change point color point_args = list(mapping = aes(color = point_color))) v1 We will change the default colors to be more informative. Points in the “down” group will be #5555ff (blue), points in the “up” group will be red3, and points in the “NS” group will be lightgrey. We will also remove the legend, since it doesn’t add much information. # Change colors v1 + scale_color_manual(values = c(&quot;#5555ff&quot;, &quot;red3&quot;, &quot;lightgrey&quot;), breaks = c(&quot;down&quot;, &quot;up&quot;, &quot;NS&quot;)) + theme(legend.position = &quot;none&quot;) # do not show legend 7.5.5 Multiple volcano plots For results generated by limma_contrasts, we should make separate plots for each comparison with facet_wrap or facet_grid. # Basic volcano plot plot_volcano(df = t_res2, logFC = &quot;logFC&quot;, pvals = &quot;adj.P.Val&quot;, sig_threshold = 0.05) + facet_wrap(vars(contrast)) + # plot for each contrast labs(title = &quot;Volcano Plots of limma_contrasts Results&quot;) "],["upset-plots.html", "7.6 UpSet Plots", " 7.6 UpSet Plots An UpSet plot is an alternative to a Venn diagram. It is not limited to visualizing differential analysis results, though I have found this to be a common use case. Another is to compare the protein identifications between groups of samples. # Filter to significant features temp &lt;- filter(t_res2, adj.P.Val &lt; 0.05) # List of significant features by contrast input_list &lt;- split(temp$RefSeq, temp$contrast) # UpSet plot plot_upset(input_list) 216 proteins are only significant in the “Proliferative-Immunoreactive” comparison, 191 are only significant in the “Mesenchymal-Immunoreactive” comparison, 35 are significant in both the “Differentiated-Immunoreactive” and “Proliferative-Immunoreactive” comparisons, etc. "],["pathway-analysis.html", "Section 8 Pathway Analysis", " Section 8 Pathway Analysis In Section 7, we covered analysis at the individual feature level (protein, peptide, phosphoprotein, etc.). While this is useful, it is not without its own set of shortcomings. For instance, there may be no features that pass the significance threshold after correcting for multiple hypothesis testing. Alternatively, there may be many features that are statistically significant, and interpreting this list can be tedious and “prone to investigator bias toward a hypothesis of interest” (Maleki et al., 2020). Another issue is that differential analysis fails to detect subtle, yet coordinated changes in groups of related features (Subramanian et al., 2005). In order to address these, and other, issues, pathway analysis instead examines a priori defined gene sets—groups of genes that participate in the same biological pathway, share the same cellular location, etc. In this section, we will explore some common annotation databases, as well as two pathway analysis methods: Over-Representation Analysis (ORA) and Gene Set Enrichment Analysis (GSEA). References "],["annotation-databases.html", "8.1 Annotation Databases", " 8.1 Annotation Databases In this section, we will explore a few of the common annotation databases used for pathway analysis. 8.1.1 Gene Ontology The Gene Ontology (GO) database is divided into three separate domains: Biological Process, Cellular Component, and Molecular Function (see the Gene Ontology overview for more details regarding each domain). Each domain is structured as a directed acyclic graph (DAG) where nodes are terms and edges are the relations between the terms (part of, is a, has part, regulates). Nodes can be connected to multiple child and parent nodes, where the group of genes annotated to a child node is a subset of those that are annotated to its parent node(s) (2021; Goeman et al., 2008). 8.1.1.1 Semantic Similarity Due to the DAG structure of each domain, there is often redundancy in pathway analysis results. For example, suppose terms GO:0006119, GO:0009060, and GO:0046034 are significantly over-represented biological processes. GO:0009060 and GO:0046034 are the parent terms of GO:0006119. Due to this relationship, the terms likely provide much of the same information, so the inclusion of all three terms in the output is unnecessary. In order to resolve this redundancy, we can calculate the semantic similarity between pairs of GO terms, which “assesses the likeness in meaning of two concepts” (Pesquita, 2017). Basically, if two terms are highly related, we can use some other criteria (such as adjusted p-value or level in the DAG) to retain only one of the terms. Below, we use the GOSemSim package to calculate the semantic similarity between the terms. ## Calculate semantic similarity between GO terms library(GOSemSim) library(org.Hs.eg.db) # GO DATA for measuring semantic similarity. # keytype is &quot;ENTREZID&quot; by default and # information content is calculated (computeIC = TRUE) semData &lt;- godata(OrgDb = &quot;org.Hs.eg.db&quot;, ont = &quot;BP&quot;) terms &lt;- c(&quot;GO:0006119&quot;, &quot;GO:0009060&quot;, &quot;GO:0046034&quot;) # measure = &quot;Rel&quot; is the default for clusterProfiler::simplify # See code for clusterProfiler:::simplify_internal sim &lt;- mgoSim(GO1 = terms, GO2 = terms, semData = semData, measure = &quot;Rel&quot;, combine = NULL) If measure is \"Lin\", \"Jiang\", or \"Wang\", the semantic similarity of a term with itself will be 1. This is not true for the other methods. We can see from Table ?? that GO:0009060 and GO:0046034 have low semantic similarity, while GO:0006119 is highly similar to its parent terms. This makes sense because the parent terms are not related/connected in the DAG. Now that we have the semantic similarities, we can remove redundant terms. clusterProfiler has a function called simplify that will calculate semantic similarity and remove terms. By default, if there are two terms with a Wang semantic similarity greater than 0.7, simplify retains the term with the lowest adjusted p-value. See this post by Guangchuang Yu for more details on clusterProfiler::simplify. 8.1.1.2 GO Subsets/Slims Another way to handle the redundancy of GO terms is to use a GO slim, which is a subset of more general or research-relevant terms from the GO. GO slims can be downloaded or the biomaRt package can be used to access GO slim accessions. ## Create human GO slim library(biomaRt) library(clusterProfiler) # gcSample data library(dplyr) mart &lt;- useMart(biomart = &quot;ENSEMBL_MART_ENSEMBL&quot;, dataset = &quot;hsapiens_gene_ensembl&quot;) # Uncomment to determine which attributes to select in getBM() # View(listAttributes(mart)) # The GO slim columns are goslim_goa_accession and goslim_goa_description. # We will map from the Entrez IDs in gcSample to these attributes. data(gcSample) universe &lt;- unique(unlist(gcSample)) GO_slim &lt;- getBM(filters = &quot;entrezgene_id&quot;, attributes = c(&quot;entrezgene_id&quot;, &quot;goslim_goa_accession&quot;, &quot;goslim_goa_description&quot;), values = universe, # Subset to these Entrez IDs mart = mart) %&gt;% # Convert entrezgene_id from integer to character mutate_all(as.character) Unfortunately, not every GO accession maps to a domain when we use biomaRt (unsure why this is the case), so we won’t be able to separate the terms. However, there are two ways that we can still use these GO slim accessions. Either follow the steps for using fgsea::fora (Section 8.2.4) with a gene set list that has been subset to the GO slim accessions, or remove any non GO slim accessions from the final results and readjust the remaining p-values. 8.1.2 Reactome Home - Reactome Pathway Database Reactome is a manually-curated database for biological processes and pathways. As of version 80 (April 2021), it contains data on 15 species (notably, H. sapiens, M. musculus, and R. norvegicus). H. sapiens is the most highly-annotated organism with 2580 pathways. 8.1.3 KEGG The Kyoto Encyclopedia of Genes and Genomes (KEGG) KEGG: Kyoto Encyclopedia of Genes and Genomes 8.1.4 MSigDB The Molecular Signatures Database (MSigDB) is a comprehensive resource of manually-curated gene sets divided into nine collections, as of v7.5.1 (Liberzon et al., 2015). Importantly, it contains non-redundant versions of the most up-to-date Gene Ontology, Reactome, and KEGG databases. The method for eliminating term redundancy is described in the v7.0 Release Notes: We computed Jaccard coefficients for each pair of sets, and marked a pair as highly similar if its Jaccard coefficient was greater than 0.85. We then clustered highly similar sets into “chunks” using the hclust function from the R stats package according to their GO terms and applied two rounds of filtering for every “chunk”. First, we kept the largest set in the “chunk” and discarded the smaller sets. This left “chunks” of highly similar sets of identical sizes, which we further pruned by preferentially keeping the more general set (i.e., the set closest to the root of the GO ontology tree). Note: the Jaccard coefficient is used to measure the similarity of two sets, \\(A\\) and \\(B\\), and is calculated as \\(J(A, B) = \\frac{|A \\cap B|}{|A \\cup B|}\\). References "],["ora.html", "8.2 Over-Representation Analysis", " 8.2 Over-Representation Analysis 8.2.1 Overview Over-representation analysis (ORA) is used to determine which a priori defined gene sets are more present (over-represented) in a subset of “interesting” genes than what would be expected by chance (Huang et al., 2009). For example, if 10% of all genes being considered are “interesting” (statistically different between conditions, clustered together, etc.), we expect that about 10% of every gene set will be in this “interesting” group of genes. If any gene sets are significantly more present in this group, we would say they are over-represented. Note that we are not limited to analyzing genes, though that is how most databases are set up. So long as we have a feature-to-feature-set map, we can perform ORA. I recommend ORA only when GSEA is not appropriate, such as for analyzing clusters (from k-means clustering, WGCNA, Mclust, etc.), where the only information available are the group designations. See Section 8.2.3 (ORA Drawbacks) for details. 8.2.2 Mathematical Details For each gene set, an enrichment p-value is calculated using the Binomial distribution, Hypergeometric distribution, the Fisher exact test, or the Chi-square test. Although this list is not all-encompassing, these are the most popular statistical methods (Huang et al., 2009). Below is the formula for calculating the enrichment p-value for a particular gene set using the Hypergeometric distribution. \\[ P(X\\geq x) = 1 - P(X \\leq x-1) = 1 - \\sum\\limits_{i=0}^{x-1}\\frac{\\hphantom{}{M \\choose i }{N - M \\choose n-i}}{N \\choose n} \\] In this equation, \\(N\\) is the number of background genes, \\(n\\) is the number of “interesting” genes, \\(M\\) is the number of genes that are annotated to a particular gene set \\(S\\), and \\(x\\) is the number of “interesting” genes that are annotated to \\(S\\). The numerator of the sum is the number of samples of \\(n\\) genes that can be taken from a population of \\(N\\) genes where exactly \\(i\\) of the genes are annotated to \\(S\\) and \\(n-i\\) are not annotated to \\(S\\). The denominator of the sum is the total number of samples of size \\(n\\) that can be taken from a population of size \\(N\\). For example, suppose we have a list of 8000 genes, of which 400 are members of the same cluster \\(C\\). Also suppose that 100 of the 8000 genes are annotated to a particular gene set \\(S\\). Of these 100 genes, 20 are members of \\(C\\). The probability that 20 or more (up to 100) genes annotated to \\(S\\) are in cluster \\(C\\) by chance is given by \\[ P(X\\geq 20) = 1 - P(X \\leq 19) = 1-\\sum \\limits_{i=0}^{19}\\frac{\\hphantom{}{100 \\choose i}{8000 - 100 \\choose 400-i}}{8000 \\choose 400} = 7.88 \\times 10^{-8} \\] That is, it is extremely unlikely that 20 of the 100 genes from this set are grouped in cluster \\(C\\) by chance (at least, prior to adjustment for multiple comparisons). The code to calculate this p-value is phyper(q = 20 - 1, m = 400, n = 8000 - 400, k = 100, lower.tail = FALSE) After a p-value has been calculated for each of the applicable gene sets, a multiple testing adjustment should be applied. 8.2.3 Drawbacks ORA is not recommended as a follow-up to differential-expression analysis for the reasons below. Use GSEA instead, if appropriate. The choice of the threshold for statistical significance and the multiple comparison adjustment method can greatly impact the analysis (Huang et al., 2009). ORA fails to incorporate direction of change. (Are the genes in a given set mainly up or down-regulated in one condition relative to another?). It is NOT a good idea to split DEA results by the direction of change and apply ORA to the resulting subsets, unless you are specifically asking “which gene sets are over-represented when we only consider genes that are up- or down-regulated?” If few genes are in the “interesting” group, ORA may not yield useful or reliable results. For example, suppose 30 out of 8000 genes are “interesting”. 100 of the genes are annotated to a particular gene set, of which 3 are “interesting”. The associated Hypergeometric p-value is 0.006, and this set would be considered significantly over-represented at the 0.01 level (at least, prior to p-value adjustment); however, if only 2 of the genes in this set are “interesting”, this p-value increases 10-fold to 0.0536 and is no longer significant even at the 0.05 level. ORA can not be used if the input contains duplicates. For example, a single feature can not be a member of two or more groups or present multiple times in the same group. This usually happens when attempting to perform gene-level ORA on protein-level differential analysis results, and can lead to artificial over-representation if genes are counted multiple times. Instead, use GSEA and summarize the ranking metric at the gene level (take the average). 8.2.4 Examples For these examples, we will show how to perform ORA with the fgsea, clusterProfiler, ReactomePA, and GOstats packages on clustering results. The databases that we will cover are Gene Ontology Biological Processes and Reactome, and we will only consider gene sets/pathways with at least 15 and no more than 300 genes. For details on these different annotation databases, please see Section 8.1 (Annotation Databases). We will use the gcSample data from clusterProfiler and treat the entire list as the gene universe/background. Each gene is represented by a human Entrez gene ID, which is the default keytype used by the clusterProfiler functions (and the only keytype compatible with ReactomePA::enrichPathway). library(clusterProfiler) data(&quot;gcSample&quot;) # data for examples Since the genes in gcSample are not unique, we will subset to unique genes for the sake of these examples. # Need to remove duplicates for the examples all_genes &lt;- unlist(gcSample) universe &lt;- all_genes[Biobase::isUnique(all_genes)] # all unique genes # List with only unique genes gcUnique &lt;- lapply(gcSample, function(group_i) { group_i[group_i %in% universe] }) 8.2.4.1 ORA with fgsea The fgsea package can be used to perform over-representation analysis with the fora function, which applies the hypergeometric test. It requires a list of gene sets or pathways, a vector of “interesting” genes to test, and a gene universe vector. For clustering results, we can run this function in lapply to test each cluster. For this example, we will perform ORA on the non-redundant Gene Ontology biological processes (GO-BP) sets from MSigDB, but any database can be used. We first need to get the list of gene sets; we do this with the msigdbr package (Section 8.1.4). We use msigdbr_collections to determine the category and subcategory and msigdbr to fetch the data. # MSigDB R package library(msigdbr) msigdbr::msigdbr_collections() # available collections # Subset to Human GO-BP sets BP_db &lt;- msigdbr(species = &quot;Homo sapiens&quot;, category = &quot;C5&quot;, subcategory = &quot;GO:BP&quot;) head(BP_db) # Convert to a list of gene sets BP_conv &lt;- unique(BP_db[, c(&quot;entrez_gene&quot;, &quot;gs_exact_source&quot;)]) BP_list &lt;- split(x = BP_conv$entrez_gene, f = BP_conv$gs_exact_source) # First ~6 IDs of first 3 terms lapply(head(BP_list, 3), head) We have all the required input, so we can move on to ORA. In order to perform ORA on each cluster, we can wrap fora in lapply. ## Cluster GO-BP ORA with fgsea package library(fgsea) library(dplyr) # For each cluster i, perform ORA fgsea_ora &lt;- lapply(seq_along(gcUnique), function(i) { fora(pathways = BP_list, genes = gcUnique[[i]], # genes in cluster i universe = universe, # all genes minSize = 15, maxSize = 500) %&gt;% mutate(cluster = names(gcUnique)[i]) # add cluster column }) %&gt;% data.table::rbindlist() %&gt;% # combine tables filter(padj &lt; 0.05) %&gt;% arrange(cluster, padj) %&gt;% # Add additional columns from BP_db left_join(distinct(BP_db, gs_subcat, gs_exact_source, gs_name, gs_description), by = c(&quot;pathway&quot; = &quot;gs_exact_source&quot;)) %&gt;% # Reformat descriptions mutate(gs_name = sub(&quot;^GOBP_&quot;, &quot;&quot;, gs_name), gs_name = gsub(&quot;_&quot;, &quot; &quot;, gs_name)) # First 6 rows head(fgsea_ora) See ?fora for a description of the output. The base output does not include term descriptions, so we had to add those ourselves. 8.2.4.2 ORA with clusterProfiler/ReactomePA clusterProfiler and ReactomePA are convenience packages that use fgsea and AnnotationDbi as the basis for their pathway analysis functions. The functions are a bit more user-friendly, as the user does not need to fetch the gene lists themselves, but they are much slower, and the resulting objects are not simple data.frames. clusterProfiler provides the enrichGO and enrichKEGG functions for GO and KEGG ORA, respectively (among others). ReactomePA provides the enrichPathway function for Reactome pathway ORA. For other databases, the clusterProfiler::enricher function can be used (though this is slower than just using fgsea::fora with a list of gene sets). To perform ORA on clustering results, we use clusterProfiler::compareCluster and tell it to use enrichGO as the ORA function. ## Cluster GO-BP ORA with clusterProfiler package cp_ora &lt;- compareCluster( geneClusters = gcUnique, fun = &quot;enrichGO&quot;, # ORA function to apply to each cluster # Arguments below are passed to enrichGO OrgDb = &quot;org.Hs.eg.db&quot;, keyType = &quot;ENTREZID&quot;, ont = &quot;BP&quot;, # BP, CC, MF, or ALL for all ontologies pvalueCutoff = 0.05, qvalueCutoff = 1, # do not filter by q-value pAdjustMethod = &quot;BH&quot;, # p-values are adjusted within clusters universe = universe, # all genes minGSSize = 15, maxGSSize = 500 ) # First 6 entries sorted by cluster and p-value cp_ora@compareClusterResult %&gt;% arrange(Cluster, pvalue) %&gt;% head() Unlike the fgsea::fora results, these include the description of each term. As for the other columns: GeneRatio is the same as overlap (from the fora results) divided by the cluster size, BgRatio is the set size divided by the universe size, pvalue is the raw p-value, p.adjust is the BH-adjusted p-value, qvalue is the q-value, geneID is the same as overlapGenes from fora, and Count is the overlap size. Below is an example of how to perform Reactome ORA with ReactomePA::enrichPathway. ## Reactome ORA with ReactomePA package library(ReactomePA) react_ora &lt;- compareCluster( geneClusters = gcUnique, fun = &quot;enrichPathway&quot;, # ORA function to apply to each cluster # Arguments below are passed to enrichPathway organism = &quot;human&quot;, pvalueCutoff = 1, # Do not filter by p-value qvalueCutoff = 1, # Do not filter by q-value pAdjustMethod = &quot;BH&quot;, # p-values are adjusted within clusters universe = universe, # all genes minGSSize = 15, maxGSSize = 500 ) # First 6 rows head(react_ora@compareClusterResult) 8.2.4.3 ORA with GOstats In the previous ORA examples, the Hypergeometric test is performed independently for each gene set; however, this does not capture the relationship between GO terms (described in Section 8.1.1). Since “each GO term inherits all annotations from its more specific descendants,” results tend to be redundant (except when using MSigDB), as they include directly-related GO terms with a high degree of overlap (S. Falcon et al., 2007). One way to handle this is with a procedure that conditions on the GO structure, like the one described by S. Falcon and R. Gentleman (2007): Given a subgraph of one of the three GO ontologies [BP, MF, or CC], we test the leaves of the graph, that is, those terms with no child terms. Before testing the terms whose children have already been tested, we remove all genes annotated at significant children [pvalueCutoff = 0.05 in the code below] from the parent’s gene list. This continues until all terms have been tested. This approach is implemented in the GOstats package by setting conditional = TRUE when creating a new object of class GOHyperGParams (See help(\"GOHyperGParams-class\", package = \"Category\") for more details). Below, we will perform GO-BP ORA just for the first cluster of gcUnique because it is time-consuming, but this could be wrapped in lapply to get results for each cluster (like in Section 8.2.4.1). ## Cluster GO-BP ORA with GOstats package library(GOstats) library(org.Hs.eg.db) library(dplyr) # For cluster 1, perform conditional ORA gostats_ora &lt;- new(Class = &quot;GOHyperGParams&quot;, ontology = &quot;BP&quot;, geneIds = gcUnique[[1]], universeGeneIds = universe, annotation = &quot;org.Hs.eg.db&quot;, pvalueCutoff = 0.05, testDirection = &quot;over&quot;, conditional = TRUE, # condition on GO structure minSizeCutoff = 15, maxSizeCutoff = 500) %&gt;% hyperGTest() %&gt;% # Hypergeometric testing summary() %&gt;% # extract results # adjust p-values mutate(Padj = p.adjust(Pvalue, method = &quot;BH&quot;)) %&gt;% filter(Padj &lt; 0.05) %&gt;% arrange(Padj) # First 6 rows head(gostats_ora) If we compare this table to the results from the other packages, we see that only GO:0007600 and GO:0061844 from the top 6 terms made it into the above table. References "],["gsea.html", "8.3 Gene Set Enrichment Analysis", " 8.3 Gene Set Enrichment Analysis 8.3.1 Overview (More details to be added at a later date.) Gene set enrichment analysis (GSEA) is a rank-based approach that determines whether predefined groups of genes/proteins/etc. are primarily up or down in one condition relative to another (Vamsi K. Mootha et al., 2003; Subramanian et al., 2005). It is typically performed as a follow-up to differential analysis, and is preferred to ORA (Section 8.2). 8.3.2 Examples These examples will show how to run Fast GSEA (FGSEA) in R, which is based on the gene permutation approach (Korotkevich et al., 2016). The input of FGSEA is a list of gene sets/pathways to check and a uniquely-named vector of ranking metric values sorted in descending order. The ranking metric that we will use is \\(-log_{10}(\\text{p-value}) * sign(\\text{logFC})\\), but we could have easily used t-statistics or some other metric. We will perform differential analysis on the cptac_oca data from the MSnSet.utils package and use the results to create the ranking metric vector. We start off by remapping features from RefSeq to Entrez ID. ## Fetch REFSEQ to ENTREZID conversion table library(MSnID) conv_tbl &lt;- fetch_conversion_table(organism_name = &quot;Homo sapiens&quot;, from = &quot;REFSEQ&quot;, to = &quot;ENTREZID&quot;) head(conv_tbl) Now, we will create the differential analysis results and add the ENTREZID column. library(MSnSet.utils) data(&quot;cptac_oca&quot;) m1 &lt;- oca.set # Differential analysis res &lt;- limma_a_b(eset = m1, model.str = &quot;~ PLATINUM.STATUS&quot;, coef.str = &quot;PLATINUM.STATUS&quot;) # table(res$adj.P.Val &lt; 0.05) # 0 # hist(res$P.Value, breaks = seq(0, 1, 0.05)) # looks uniform head(res) library(dplyr) # Add ENTREZID column res &lt;- res %&gt;% mutate(REFSEQ = sub(&quot;\\\\.\\\\d+&quot;, &quot;&quot;, rownames(.))) %&gt;% left_join(conv_tbl, by = &quot;REFSEQ&quot;) head(res) We need one ranking metric value per Entrez ID, so we will calculate the ranking metric and then take the gene-wise average. Then, we sort the genes in descending order by their ranking metric values and convert to a named vector called geneList. ## Ranking metric vector for GSEA geneList &lt;- res %&gt;% filter(!is.na(ENTREZID), !is.na(logFC)) %&gt;% mutate(ranking_metric = -log10(P.Value)*sign(logFC)) %&gt;% group_by(ENTREZID) %&gt;% summarise(ranking_metric = mean(ranking_metric, na.rm = TRUE)) %&gt;% arrange(-ranking_metric) %&gt;% # sort descending (important!) tibble::deframe() # convert to named vector head(geneList) tail(geneList) Now that we have the uniquely-named ranking metric vector, we can proceed with FGSEA. For these examples, we will show how to perform FGSEA with the fgsea, clusterProfiler, and ReactomePA packages. The databases that we will cover are Gene Ontology Biological Processes and Reactome, and we will only consider gene sets/pathways with at least 15 and no more than 500 genes. The maximum gene set size, as well as the number of permutations, affect the normalized enrichment scores and p-values. For details on these different annotation databases, please see Section 8.1 (Annotation Databases). 8.3.2.1 GSEA with fgsea To perform FGSEA with the fgsea package, we need a list of gene sets/pathways and the ranking metric vector. Below is one way to get the gene set list. # MSigDB R package library(msigdbr) msigdbr::msigdbr_collections() # available collections # Subset to Human GO-BP sets BP_db &lt;- msigdbr(species = &quot;Homo sapiens&quot;, category = &quot;C5&quot;, subcategory = &quot;GO:BP&quot;) head(BP_db) # Convert to a list of gene sets BP_conv &lt;- unique(BP_db[, c(&quot;entrez_gene&quot;, &quot;gs_exact_source&quot;)]) BP_list &lt;- split(x = BP_conv$entrez_gene, f = BP_conv$gs_exact_source) # First ~6 IDs of first 3 terms lapply(head(BP_list, 3), head) The fgseaMultilevel function uses the adaptive multilevel split Monte Carlo approach described in the original FGSEA paper (Korotkevich et al., 2016). ## GO-BP FGSEA with fgsea package library(fgsea) set.seed(99) system.time( # keep track of elapsed time fgsea_res &lt;- fgseaMultilevel(pathways = BP_list, stats = geneList, minSize = 15, maxSize = 500, eps = 0, nPermSimple = 10000) ) # First 6 rows with lowest enrichment p-values fgsea_res %&gt;% # Add additional columns from BP_db left_join(distinct(BP_db, gs_subcat, gs_exact_source, gs_name, gs_description), by = c(&quot;pathway&quot; = &quot;gs_exact_source&quot;)) %&gt;% # Reformat descriptions mutate(gs_name = sub(&quot;^GOBP_&quot;, &quot;&quot;, gs_name), gs_name = gsub(&quot;_&quot;, &quot; &quot;, gs_name)) %&gt;% arrange(padj) %&gt;% head(8) See ?fgseaMultilevel for a description of the output. The output does not include term descriptions, so we had to add those ourselves. 8.3.2.2 GSEA with clusterProfiler/ReactomePA See Section 8.2.4.2 to get a better understanding of these packages. clusterProfiler provides the gseGO and gseKEGG functions (among others) for FGSEA of the GO and KEGG databases, respectively. They are essentially more user-friendly wrapper functions that make use of the fgsea and AnnotationDbi package, but they tend to be much slower. ## GO-BP FGSEA with clusterProfiler package library(clusterProfiler) system.time( # keep track of elapsed time cgsea_res &lt;- gseGO(geneList = geneList, ont = &quot;BP&quot;, OrgDb = &quot;org.Hs.eg.db&quot;, minGSSize = 15, maxGSSize = 500, eps = 0, nPermSimple = 10000, seed = TRUE) ) # First 8 rows with lowest enrichment p-values cgsea_res@result %&gt;% arrange(pvalue) %&gt;% head(8) Notice that the normalized enrichment scores (NES) are not quite the same as what we got when we used fgseaMultiLevel. This has to do with the permutations being different. To increase the precision of the NES and p-values, we can increase nPermSimple, though 10,000 should be more than sufficient. Now, here is GSEA with the Reactome database using the gsePathway function from the ReactomePA package. ## Reactome FGSEA with ReactomePA package library(ReactomePA) fgsea_react &lt;- gsePathway(geneList = geneList, organism = &quot;human&quot;, minGSSize = 15, maxGSSize = 500, eps = 0, nPermSimple = 10000, seed = TRUE) # First 6 rows head(fgsea_react@result) References "],["references.html", "References", " References "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
